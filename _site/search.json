[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this section, I will install and load tidyverse and sf packages.\n\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-the-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Plotting the Geospatial Data",
    "text": "Plotting the Geospatial Data\n\nplot(mpsz)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#geospatial-data",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Geospatial Data",
    "text": "Geospatial Data\n\nmpsz <- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\celinderr\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#examine-content-of-mpsz",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#examine-content-of-mpsz",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Examine content of mpsz",
    "text": "Examine content of mpsz\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#import-attribute-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#import-attribute-data",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Import Attribute Data",
    "text": "Import Attribute Data\n\npopdata <- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-wrangling",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "1) Data Wrangling",
    "text": "1) Data Wrangling\n\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%>%\nmutate(`AGED`=rowSums(.[16:21])) %>%\nmutate(`TOTAL`=rowSums(.[3:21])) %>%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#join-geospatial-and-attribute-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#join-geospatial-and-attribute-data",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2) Join geospatial and attribute data",
    "text": "2) Join geospatial and attribute data\n\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %>%\n  filter(`ECONOMY ACTIVE` > 0)\n\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#qtmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#qtmap",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "qtmap()",
    "text": "qtmap()\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#tmap-elements",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#tmap-elements",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "tmap() elements",
    "text": "tmap() elements\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\nDrawing base map\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\nDrawing choropleth map (tm_polygons)\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\nDrawing choropleth map (tm_fill and tm_border)\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#using-different-classification-methods-compare-the-differences",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#using-different-classification-methods-compare-the-differences",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Using different classification methods, compare the differences",
    "text": "Using different classification methods, compare the differences\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 7,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#same-classification-different-bins",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#same-classification-different-bins",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Same classification, different bins",
    "text": "Same classification, different bins\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#obtain-descriptive-statistics-before-setting-break-points",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#obtain-descriptive-statistics-before-setting-break-points",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Obtain descriptive statistics before setting break points",
    "text": "Obtain descriptive statistics before setting break points\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6519  0.7025  0.7742  0.7645 19.0000      92"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plot-choropleth-map-using-breakpoints",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plot-choropleth-map-using-breakpoints",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Plot choropleth map using breakpoints",
    "text": "Plot choropleth map using breakpoints\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#using-colour-brewer-palette",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#using-colour-brewer-palette",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Using Colour Brewer Palette",
    "text": "Using Colour Brewer Palette\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#map-legend",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#map-legend",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Map Legend",
    "text": "Map Legend\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#map-style",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#map-style",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Map Style",
    "text": "Map Style\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\nCartographic Furniture\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n#Reset default\n\ntmap_style(\"white\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#by-assigning-multiple-values-to-at-least-one-of-the-aesthetic-arguments-ncol-in-tm_fill",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#by-assigning-multiple-values-to-at-least-one-of-the-aesthetic-arguments-ncol-in-tm_fill",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "By assigning multiple values to at least one of the aesthetic arguments (ncol in tm_fill())",
    "text": "By assigning multiple values to at least one of the aesthetic arguments (ncol in tm_fill())\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#more-than-one-aesthetic-arguments",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#more-than-one-aesthetic-arguments",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "More than one aesthetic arguments",
    "text": "More than one aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#by-defining-a-group-by-variable-in-tm_facets",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#by-defining-a-group-by-variable-in-tm_facets",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "By defining a group-by variable in tm_facets()",
    "text": "By defining a group-by variable in tm_facets()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#by-creating-multiple-stand-alone-maps-with-tmap_arrange",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#by-creating-multiple-stand-alone-maps-with-tmap_arrange",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "By creating multiple stand-alone maps with tmap_arrange()",
    "text": "By creating multiple stand-alone maps with tmap_arrange()\n\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#instead-of-creating-small-multiple-choropleth-map-you-can-also-use-selection-funtion-to-map-spatial-objects-meeting-the-selection-criterion.",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#instead-of-creating-small-multiple-choropleth-map-you-can-also-use-selection-funtion-to-map-spatial-objects-meeting-the-selection-criterion.",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "Instead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.",
    "text": "Instead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "pacman::p_load(maptools, sf, raster, spatstat, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#these-geospatial-data-uses-an-svy21-projection-system.",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#these-geospatial-data-uses-an-svy21-projection-system.",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "These geospatial data uses an SVY21 projection system.",
    "text": "These geospatial data uses an SVY21 projection system.\n\nAlternatively, a pin map could also be created.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#learning-to-convert-simple-feature-sf.data-frame-to-sps-spatial-class",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#learning-to-convert-simple-feature-sf.data-frame-to-sps-spatial-class",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Learning to convert simple feature )sf.data frame to sp’s Spatial* Class",
    "text": "Learning to convert simple feature )sf.data frame to sp’s Spatial* Class\n\nas_Spatial() of sf package (to convert three geospatial data from simple feature data frame to sp’s Spatial* class)\n\nchildcare <- as_Spatial(childcare_sf)\nmpsz <- as_Spatial(mpsz_sf)\nsg <- as_Spatial(sg_sf)\n\n\n\nDisplay information\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>018989</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>08F73931F4A691F4</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \nmax values  : kml_999,                  <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>829646</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>RAFFLES KIDZ @ PUNGGOL PTE LTD</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>379D017BF244B0FA</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#learning-to-convert-sps-spatial-class-to-generic-sp-format",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#learning-to-convert-sps-spatial-class-to-generic-sp-format",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Learning to convert sp’s Spatial* Class to generic sp format",
    "text": "Learning to convert sp’s Spatial* Class to generic sp format\n\nspstat requires analytical data in ppp object form\n\n\nThere is no direct way to convert a Spatial* Classes into ppp object.\n\n\nWe need to convert Spatial classes* into Spatial object first.\n\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sp <- as(sg, \"SpatialPolygons\")\nmpsz_sp <- as(mpsz, \"SpatialPolygons\")\n\n\n\nDisplay the sp objects properties\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \n\n\n\nmpsz_sp\n\nclass       : SpatialPolygons \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#learning-to-convert-generic-sp-format-into-spatstats-ppp-format",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#learning-to-convert-generic-sp-format-into-spatstats-ppp-format",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Learning to convert generic sp format into spatstat’s ppp format",
    "text": "Learning to convert generic sp format into spatstat’s ppp format\n\nas.ppp() of spatstat (to convert spatial data into spatstat’s ppp object format)\n\nchildcare_ppp <- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#plot-and-observe-difference",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#plot-and-observe-difference",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Plot and observe difference",
    "text": "Plot and observe difference\n\nplot(childcare_ppp)\n\n\n\n\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#handling-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#handling-duplicated-points",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Handling Duplicated Points",
    "text": "Handling Duplicated Points\n\nCheck for duplication\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\n\n\nCount number of co-indicence point\n\nmultiplicity()\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\n\n\n\nCheck how many locations have more than one point event\n\nsum(multiplicity(childcare_ppp) > 1)\n\n[1] 128\n\n\n\n\nView locations of duplicated point events\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\n\nAlways remember to switch back tmap_mode to plot\n\ntmap_mode('plot')\n\ntmap mode set to plotting"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#deletion-of-duplicates-some-useful-point-events-will-be-lost",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#deletion-of-duplicates-some-useful-point-events-will-be-lost",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "1) Deletion of duplicates: Some useful point events will be lost",
    "text": "1) Deletion of duplicates: Some useful point events will be lost"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#jittering-will-add-a-small-perturbation-to-the-duplicated-points-so-that-they-do-not-occupy-the-same-exact-space",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#jittering-will-add-a-small-perturbation-to-the-duplicated-points-so-that-they-do-not-occupy-the-same-exact-space",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "2) Jittering: will add a small perturbation to the duplicated points so that they do not occupy the same exact space",
    "text": "2) Jittering: will add a small perturbation to the duplicated points so that they do not occupy the same exact space"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#make-each-point-unique-and-then-attach-duplicates-of-points-to-the-patterns-as-marks-as-attributes-of-the-points.-would-need-analytical-techniques-that-take-into-account-these-marks",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#make-each-point-unique-and-then-attach-duplicates-of-points-to-the-patterns-as-marks-as-attributes-of-the-points.-would-need-analytical-techniques-that-take-into-account-these-marks",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "3) Make each point “unique” and then attach duplicates of points to the patterns as marks, as attributes of the points. Would need analytical techniques that take into account these marks",
    "text": "3) Make each point “unique” and then attach duplicates of points to the patterns as marks, as attributes of the points. Would need analytical techniques that take into account these marks"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#jittering-approach",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#jittering-approach",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Jittering approach",
    "text": "Jittering approach\n\nchildcare_ppp_jit <- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nCheck for any duplicated point in this geospatial data\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#good-practice-to-confine-the-analysis-with-a-geographical-area-like-singapore-boundary-when-analysing-spatial-point-patterns",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#good-practice-to-confine-the-analysis-with-a-geographical-area-like-singapore-boundary-when-analysing-spatial-point-patterns",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Good practice to confine the analysis with a geographical area like Singapore boundary (when analysing spatial point patterns)",
    "text": "Good practice to confine the analysis with a geographical area like Singapore boundary (when analysing spatial point patterns)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#owin-object-of-spatstat-specially-designed-to-represent-this-polygonal-region",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#owin-object-of-spatstat-specially-designed-to-represent-this-polygonal-region",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "owin object of spatstat – specially designed to represent this polygonal region",
    "text": "owin object of spatstat – specially designed to represent this polygonal region\n\nsg_owin <- as(sg_sp, \"owin\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#display-output-object",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#display-output-object",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "display output object",
    "text": "display output object\n\nplot(sg_owin)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#summary-of-base-r",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#summary-of-base-r",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "summary() of base R",
    "text": "summary() of base R\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#extract-childcare-events-that-are-located-within-singapore",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#extract-childcare-events-that-are-located-within-singapore",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Extract childcare events that are located within Singapore",
    "text": "Extract childcare events that are located within Singapore\n\nchildcareSG_ppp = childcare_ppp[sg_owin]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#ouput-object",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#ouput-object",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Ouput object",
    "text": "Ouput object\n\nsummary(childcareSG_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 2.063463e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#plot-newly-derived-childcare_ppp",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#plot-newly-derived-childcare_ppp",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Plot newly derived childcare_ppp",
    "text": "Plot newly derived childcare_ppp\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#kernel-density-estimation-kde",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#kernel-density-estimation-kde",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Kernel Density Estimation (KDE)",
    "text": "Kernel Density Estimation (KDE)\n\ndensity() of spatstat:\n\nkde_childcareSG_bw <- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\n\n\n\nPlot KDE derived\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\nObservation: Density values of output range from 0 to 0.000035 which is way too small to comprehend. This is because the default measurement f SVY21 is in meters. Hence, the density values computed is in “number of points per square meter”.\n\n\n\nCan retrieve bandwidth used to compute the KDE layer by:\n\nbw <- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#rescaling-kde-values",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#rescaling-kde-values",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Rescaling KDE values",
    "text": "Rescaling KDE values\n\nrescale() to convert unit of measurement from meter to kilometer\n\nchildcareSG_ppp.km <- rescale(childcareSG_ppp, 1000, \"km\")\n\n\n\nrerun density() using resale data set and plot output KDE map\n\nkde_childcareSG.bw <- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nplot(kde_childcareSG.bw)\n\n\n\n\n\nNote: output image identical to previous output, only changes the data values in the legend"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#working-with-different-automatic-bandwidth-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#working-with-different-automatic-bandwidth-methods",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Working with different automatic bandwidth methods",
    "text": "Working with different automatic bandwidth methods\n\nOther than bw.diggle(), there are other spatstat functions that can be used to determine bandwidth such as bw.CvL(), bw.scott(), and bw.ppl().\n\nbw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#comparison-of-output-between-bw.diggle-and-bw.ppl",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#comparison-of-output-between-bw.diggle-and-bw.ppl",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Comparison of output between bw.diggle and bw.ppl",
    "text": "Comparison of output between bw.diggle and bw.ppl\n\nkde_childcareSG.ppl <- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#working-with-different-kernel-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#working-with-different-kernel-methods",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Working with different kernel methods",
    "text": "Working with different kernel methods\n\nBy default, kernel method used in density.ppp() is gaussian. Other methods: Epanechnikov, Quartic and Dics.\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\npoint-in-polygon test had difficulty with 215 points (total score not 0 or 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-kde-by-using-fixed-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-kde-by-using-fixed-bandwidth",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Computing KDE by using fixed bandwidth",
    "text": "Computing KDE by using fixed bandwidth\n\nNext, compute a KDE layer by defining a bandwidth of 600 meter.\n\n\nSigma value is 0.6 in the code below as the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_600 <- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nplot(kde_childcareSG_600)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-kde-by-using-adaptive-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-kde-by-using-adaptive-bandwidth",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Computing KDE by using adaptive bandwidth",
    "text": "Computing KDE by using adaptive bandwidth\n\nFixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units, eg. urban vs rural. To overcome this, use adaptive bandwidth.\n\n\ndensity_adaptive() of spatstat (to derive adaptive kernel density estimation)\n\nkde_childcareSG_adaptive <- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nWarning: point-in-polygon test had difficulty with 215 points (total score not\n0 or 1)\n\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\nCompare the fixed and adaptive kernel density estimation outputs\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#result-same-but-convert-it-so-that-it-is-suitable-for-mapping-purposes",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#result-same-but-convert-it-so-that-it-is-suitable-for-mapping-purposes",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Result same, but convert it so that it is suitable for mapping purposes",
    "text": "Result same, but convert it so that it is suitable for mapping purposes\n\ngridded_kde_childcareSG_bw <- as.SpatialGridDataFrame.im(kde_childcareSG.bw)\nspplot(gridded_kde_childcareSG_bw)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#converting-gridded-output-into-raster",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#converting-gridded-output-into-raster",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Converting gridded output into raster",
    "text": "Converting gridded output into raster\n\nraster() of raster package (to convert gridded density objects into RasterLayer object)\n\nkde_childcareSG_bw_raster <- raster(gridded_kde_childcareSG_bw)\n\n\n\nProperties of kde_childcareSG_bw_raster RasterLayer\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\nNote: crs property is NA"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#code-chunk-to-include-crs-infotrmation-on-kde_childcaresg_bw_raster-rasterlayer",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#code-chunk-to-include-crs-infotrmation-on-kde_childcaresg_bw_raster-rasterlayer",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Code chunk to include CRS infotrmation on kde_childcareSG_bw_raster RasterLayer",
    "text": "Code chunk to include CRS infotrmation on kde_childcareSG_bw_raster RasterLayer\n\nprojection(kde_childcareSG_bw_raster) <- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\nNote: crs property is completed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#firstly",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#firstly",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Firstly,",
    "text": "Firstly,\n\ntmap package to display raster in cartographic quality map\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\nVariable(s) \"v\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\nNotice raster values are encoded explicitly onto the raster pixel using the values in the “v” field."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#extracting-study-area",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#extracting-study-area",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Extracting study area",
    "text": "Extracting study area\n\nExtract target planning areas\n\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\n\n\nPlot target planning areas\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\nplot(tm, main = \"Tampines\")\nplot(ck, main = \"Choa Chu Kang\")\nplot(jw, main = \"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#converting-the-spatial-point-data-frame-into-generic-sp-format",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#converting-the-spatial-point-data-frame-into-generic-sp-format",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Converting the spatial point data frame into generic sp format",
    "text": "Converting the spatial point data frame into generic sp format\n\nConvert SpatialPolygonsDataFrame layers into generic spatialpolygon layers\n\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#creating-owin-object-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#creating-owin-object-1",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Creating owin object",
    "text": "Creating owin object\n\nConvert SpatialPolygons objects into owin objects that is required by spatstat\n\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#combine-childcare-points-and-study-area",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#combine-childcare-points-and-study-area",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Combine childcare points and study area",
    "text": "Combine childcare points and study area\n\nAble to extract code childcare that is within the specific region to do our analysis later on\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\n\n\nrescale() used to transform the unit of measurement from metre to kilometre\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#plot-study-areas-and-locations-of-childcare-centres",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#plot-study-areas-and-locations-of-childcare-centres",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Plot study areas and locations of childcare centres",
    "text": "Plot study areas and locations of childcare centres\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-fixed-bandwidth-kde",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-fixed-bandwidth-kde",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Computing fixed bandwidth KDE",
    "text": "Computing fixed bandwidth KDE\n\nFor comparison, we will use 250m as the bandwidth.\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#test-hypotheses",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#test-hypotheses",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Test hypotheses:",
    "text": "Test hypotheses:\n\nH0 = Childcare centre distribution are randomly distributed\n\n\nH1 = Childcare centre distribution are not randomly distributed"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#the-95-confidence-interval-will-be-used.",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#the-95-confidence-interval-will-be-used.",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "The 95% confidence interval will be used.",
    "text": "The 95% confidence interval will be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#testing-spatial-point-patterns-using-clarks-and-evans-test",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#testing-spatial-point-patterns-using-clarks-and-evans-test",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Testing spatial point patterns using Clarks and Evans Test",
    "text": "Testing spatial point patterns using Clarks and Evans Test\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 11 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 33 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 11 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 10 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 11 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 7 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 11 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 10 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 29 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 12 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 28 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 11 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 26 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 33 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 10 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 30 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 33 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 22 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 27 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 19 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 23 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 24 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 16 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 14 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 15 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 25 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 29 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 17 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 10 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 21 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 13 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 18 points (total score not 0\nor 1)\n\n\nWarning: point-in-polygon test had difficulty with 20 points (total score not 0\nor 1)\n\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 99 simulations of CSR with fixed n\n\ndata:  childcareSG_ppp\nR = 0.54756, p-value = 0.01\nalternative hypothesis: clustered (R < 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#clarks-and-evans-test-choa-chu-kang-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#clarks-and-evans-test-choa-chu-kang-planning-area",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Clarks and Evans Test: Choa Chu Kang planning area",
    "text": "Clarks and Evans Test: Choa Chu Kang planning area\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 999 simulations of CSR with fixed n\n\ndata:  childcare_ck_ppp\nR = 0.89409, p-value = 0.034\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#clarks-and-evans-test-tampines-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#clarks-and-evans-test-tampines-planning-area",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "Clarks and Evans Test: Tampines planning area",
    "text": "Clarks and Evans Test: Tampines planning area\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 999 simulations of CSR with fixed n\n\ndata:  childcare_tm_ppp\nR = 0.78958, p-value = 0.002\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "",
    "text": "pacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#import-shapefile-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#import-shapefile-into-r-environment",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "Import shapefile into R environment",
    "text": "Import shapefile into R environment\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\celinderr\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#import-csv-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#import-csv-into-r-environment",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "Import csv into R environment",
    "text": "Import csv into R environment\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#left_join-of-dplyr-package",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#left_join-of-dplyr-package",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "left_join of dplyr() package",
    "text": "left_join of dplyr() package\n\nhunan <- left_join(hunan,hunan2012)%>%\n  select(1:4, 7, 15)\n\nJoining, by = \"County\""
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#prepare-basemap-and-choropleth-map-to-show-distribution-of-gdppc-2012",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#prepare-basemap-and-choropleth-map-to-show-distribution-of-gdppc-2012",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "Prepare basemap and choropleth map to show distribution of GDPPC 2012",
    "text": "Prepare basemap and choropleth map to show distribution of GDPPC 2012"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#qtm-of-tmap-package",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#qtm-of-tmap-package",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "qtm() of tmap package",
    "text": "qtm() of tmap package\n\nbasemap <- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc <- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-queen-contiguity-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-queen-contiguity-based-neighbours",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "Computing (QUEEN) contiguity based neighbours",
    "text": "Computing (QUEEN) contiguity based neighbours\n\nwm_q <- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\n\nObservation: 88 area units in Hunan, most connected unit has 11 neighbours, 2 area units with only 1 neighbour.\n\n\nFor each polygon in our polygon object, wm_q lists all the neighbouring polygons.\n\n\nEg. to see neighbours for the first polygon in the object:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\n\nObservation: Polygon 1 has 5 neighbours. Numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class\n\n\n\nto retrieve county name of Polygon ID=1:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\n\n\nto reveal county name of 5 neighbours:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\n\n\nto retrieve GDPPC of above 5 countries:\n\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\n\nto display the complete weight matrix (str())\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-rook-contiguity-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-rook-contiguity-based-neighbours",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "Creating (ROOK) contiguity based neighbours",
    "text": "Creating (ROOK) contiguity based neighbours\n\nto compute ROOK contiguinity weight matrix\n\nwm_r <- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\n\nObservations: 88 area units in Hunan, most connected area unit has 10 neighbours, 2 units with only 1 neighbour"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-contiguity-weights",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-contiguity-weights",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "Visualising contiguity weights",
    "text": "Visualising contiguity weights\n\nA connectivity graph takes a point and displays a line to each neighbouring point.\n\n\nNow is polygons form, so we will need to get the points in order to make the connectivity graphs.\n\n\nMost typical method is polygon centroids, calculated in the sf package before moving onto the graphs"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-latitude-and-longitude-of-polygon-centroids",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-latitude-and-longitude-of-polygon-centroids",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "Getting latitude and longitude of polygon centroids",
    "text": "Getting latitude and longitude of polygon centroids\n\n- Need points to associate with each polygon before making connectivity graph,\n\n\n- Need coordinates in a separate data frame for this\n\n\n- We will use a mapping function – applies a given function to each element of a vector and returns a vector of the same length\n\nInput vector: geometry column of us.bound\n\n\nFunction: st_centroid\n\n\nmap_dbl of purrr package\n\n\n\nTo get longitude values -> map st_centroid function over geometry column of us.bound and access longitude value through [] and 1. (First value in each centroid is the longitude)\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\n\n\nGet latitude, the second value per each centroid\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#use-cbind-to-put-latitude-and-longitude-into-the-same-object",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#use-cbind-to-put-latitude-and-longitude-into-the-same-object",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "Use cbind to put latitude and longitude into the same object",
    "text": "Use cbind to put latitude and longitude into the same object\n\ncoords <- cbind(longitude, latitude)\n\n\nCheck first few observations to see if things are formatted correctly\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands-on 8; Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "pacman::p_load(olsrr, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#updating-crs-information",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#updating-crs-information",
    "title": "Hands-on 8; Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Updating CRS information",
    "text": "Updating CRS information\n\nmpsz_svy21 <- st_transform(mpsz, 3414)\n\n\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reveal-extent-of-mpsz_svy21-using-st_bbox-of-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reveal-extent-of-mpsz_svy21-using-st_bbox-of-sf-package",
    "title": "Hands-on 8; Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Reveal extent of mpsz_svy21 using st_bbox of sf package",
    "text": "Reveal extent of mpsz_svy21 using st_bbox of sf package\n\nst_bbox(mpsz_svy21)\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#aspatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#aspatial-data-wrangling",
    "title": "Hands-on 8; Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Aspatial Data Wrangling",
    "text": "Aspatial Data Wrangling\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nRows: 1436 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (23): LATITUDE, LONGITUDE, POSTCODE, SELLING_PRICE, AREA_SQM, AGE, PROX_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nDisplay data structure of it\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             <dbl> 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            <dbl> 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             <dbl> 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\n\nSee data in x-coord column\n\nhead(condo_resale$LONGITUDE)\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\n\n\nSee data in y-coord column\n\nhead(condo_resale$LATITUDE)\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\n\n\nDisplay summary statistics with summary() of base R\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#convert-aspatial-data-into-sf-object",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#convert-aspatial-data-into-sf-object",
    "title": "Hands-on 8; Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Convert aspatial data into sf object",
    "text": "Convert aspatial data into sf object\n\ncondo_resale.sf <- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %>%\n  st_transform(crs=3414)\n\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLI…¹ AREA_…²   AGE PROX_…³ PROX_…⁴ PROX_…⁵ PROX_…⁶ PROX_…⁷ PROX_…⁸\n     <dbl>   <dbl>   <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1   118635 3000000     309    30    7.94   0.166   2.52     6.62   1.77   0.0584\n2   288420 3880000     290    32    6.61   0.280   1.93     7.51   0.545  0.616 \n3   267833 3325000     248    33    6.90   0.429   0.502    6.46   0.378  0.141 \n4   258380 4250000     127     7    4.04   0.395   1.99     4.91   1.68   0.382 \n5   467169 1400000     145    28   11.8    0.119   1.12     6.41   0.565  0.461 \n6   466472 1320000     139    22   10.3    0.125   0.789    5.09   0.781  0.0994\n# … with 12 more variables: PROX_MRT <dbl>, PROX_PARK <dbl>,\n#   PROX_PRIMARY_SCH <dbl>, PROX_TOP_PRIMARY_SCH <dbl>,\n#   PROX_SHOPPING_MALL <dbl>, PROX_SUPERMARKET <dbl>, PROX_BUS_STOP <dbl>,\n#   NO_Of_UNITS <dbl>, FAMILY_FRIENDLY <dbl>, FREEHOLD <dbl>,\n#   LEASEHOLD_99YR <dbl>, geometry <POINT [m]>, and abbreviated variable names\n#   ¹​SELLING_PRICE, ²​AREA_SQM, ³​PROX_CBD, ⁴​PROX_CHILDCARE, ⁵​PROX_ELDERLYCARE,\n#   ⁶​PROX_URA_GROWTH_AREA, ⁷​PROX_HAWKER_MARKET, ⁸​PROX_KINDERGARTEN"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#eda-using-statistics-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#eda-using-statistics-graphics",
    "title": "Hands-on 8; Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "EDA using statistics graphics",
    "text": "EDA using statistics graphics\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\ncondo_resale.sf <- condo_resale.sf %>%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-histogram-plots-distribution-of-variables",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-histogram-plots-distribution-of-variables",
    "title": "Hands-on 8; Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Multiple Histogram Plots distribution of variables",
    "text": "Multiple Histogram Plots distribution of variables\n\nAREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#drawing-statistical-point-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#drawing-statistical-point-map",
    "title": "Hands-on 8; Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Drawing Statistical Point Map",
    "text": "Drawing Statistical Point Map\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n\n\ntmap_options(check.and.fix = TRUE)\n\n\ntm_shape(mpsz_svy21)+\n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#simple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#simple-linear-regression-method",
    "title": "Hands-on 8; Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Simple Linear Regression Method",
    "text": "Simple Linear Regression Method\n\nIndependent variable: AREA_SQM\n\n\nDependent variable: SELLING_PRICE\n\ncondo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: < 2.2e-16\n\n\n\n\nVisualise best fit curve on scatter plot\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nObservation: few statistical outlier with relatively high selling prices"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-linear-regression-method",
    "title": "Hands-on 8; Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Multiple Linear Regression Method",
    "text": "Multiple Linear Regression Method\n\nVisualising the relationships of the independent variables\n\ncorrplot::corrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\n\n\nBuilding a hedonic pricing model using multiple linear regression method\n\ncondo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  < 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  < 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  < 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  < 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: < 2.2e-16\n\n\n\n\nPreparing Publication Quality Table: olsrr method\n\ncondo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                             Model Summary                               \n------------------------------------------------------------------------\nR                       0.807       RMSE                     755957.289 \nR-Squared               0.651       Coef. Var                    43.168 \nAdj. R-Squared          0.647       MSE                571471422208.591 \nPred R-Squared          0.638       MAE                      414819.628 \n------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\n\nPreparing Publication Quality Table: gtsummary method\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %>% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = <0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\nChecking for multicolinearity\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\n\n\nTest for Non-Linearity\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\n\n\nTest for Normality Assumption\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\n\nA more formal statistical test method:\n\nols_test_normality(condo.mlr1)\n\nWarning in ks.test.default(y, \"pnorm\", mean(y), sd(y)): ties should not be\npresent for the Kolmogorov-Smirnov test\n\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\n\n\n\n\nTesting for Spatial Autocorrelation\n\n1) join the newly created data frame with condo_resale.sf object.\n\ncondo_resale.res.sf <- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %>%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\n\n\n2) convert condo_resale.res.sf from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\n\ncondo_resale.sp <- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\nVariable(s) \"MLR_RES\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2: Data Wrangling with R",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, funModeling)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#the-geoboundaries-data-set",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#the-geoboundaries-data-set",
    "title": "In-class Exercise 2: Data Wrangling with R",
    "section": "The geoBoundaries data set",
    "text": "The geoBoundaries data set\n\ngeoNGA <- st_read(\"data/geospatial/\",\n               layer = \"geoBoundaries-NGA-ADM2\") %>%\n  st_transform(crs = 26392)\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `C:\\celinderr\\IS415-GAA\\In-class_Ex\\In-class_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#the-nga-data-set",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#the-nga-data-set",
    "title": "In-class Exercise 2: Data Wrangling with R",
    "section": "The NGA data set",
    "text": "The NGA data set\n\nNGA <- st_read(\"data/geospatial/\",\n               layer = \"nga_admbnda_adm2_osgof_20190417\") %>%\n  st_transform(crs = 26392)\n\nReading layer `nga_admbnda_adm2_osgof_20190417' from data source \n  `C:\\celinderr\\IS415-GAA\\In-class_Ex\\In-class_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\nBy examining both sf dataframe closely, we notice that NGA provide both LGA and state information. Hence, NGA data.frame will be used for the subsequent processing."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#excluding-redundant-fields",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#excluding-redundant-fields",
    "title": "In-class Exercise 2: Data Wrangling with R",
    "section": "Excluding redundant fields",
    "text": "Excluding redundant fields\n\nselect() of dplyr (to retain column 3, 4, 8, 9)\n\nNGA <- NGA %>%\n  select(c(3:4, 8:9))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#checking-for-duplicate-name",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#checking-for-duplicate-name",
    "title": "In-class Exercise 2: Data Wrangling with R",
    "section": "Checking for Duplicate Name",
    "text": "Checking for Duplicate Name\n\nduplicate() of Base R (to flag out duplicated LGA names)\n\nNGA$ADM2_EN[duplicated(NGA$ADM2_EN)==TRUE]\n\n[1] \"Bassa\"    \"Ifelodun\" \"Irepodun\" \"Nasarawa\" \"Obi\"      \"Surulere\"\n\n\n\nThe printout above shows that there are 6 LGAs with the same name. A Google search using the coordinates showed that there are LGAs with the same name but are located in different states. For instances, there is a Bassa LGA in Kogi State and a Bassa LGA in Plateau State.\n\n\nLet us correct these errors by using the code chunk below.\n\nNGA$ADM2_EN[94] <- \"Bassa, Kogi\"\nNGA$ADM2_EN[95] <- \"Bassa, Plateau\"\nNGA$ADM2_EN[304] <- \"Ifelodun, Kwara\"\nNGA$ADM2_EN[305] <- \"Ifelodun, Osun\"\nNGA$ADM2_EN[355] <- \"Irepodun, Kwara\"\nNGA$ADM2_EN[356] <- \"Irepodun, Osun\"\nNGA$ADM2_EN[519] <- \"Nasarawa, Kano\"\nNGA$ADM2_EN[520] <- \"Nasarawa, Nasarawa\"\nNGA$ADM2_EN[546] <- \"Obi, Benue\"\nNGA$ADM2_EN[547] <- \"Obi, Nasarawa\"\nNGA$ADM2_EN[693] <- \"Surulere, Lagos\"\nNGA$ADM2_EN[694] <- \"Surulere, Oyo\"\n\n\n\nConfirm that duplicated name issue address\n\nNGA$ADM2_EN[duplicated(NGA$ADM2_EN)==TRUE]\n\ncharacter(0)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#extracting-water-point-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#extracting-water-point-data",
    "title": "In-class Exercise 2: Data Wrangling with R",
    "section": "Extracting Water Point Data",
    "text": "Extracting Water Point Data\n\nExtracting functional water point\n\nwp_functional <- wp_sf_nga %>%\n  filter(status_clean %in%\n           c(\"Functional\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\n\n\nExtracting non-functional water point\n\nwp_nonfunctional <- wp_sf_nga %>%\n  filter(status_clean %in%\n           c(\"Abandoned/Decommissioned\",\n             \"Abandoned\",\n             \"Non-Functional due to dry season\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\"))\n\n\n\nExtracting water point with unknown status\n\nwp_unknown <- wp_sf_nga %>%\n  filter(status_clean == \"unknown\")\n\n\n\nPerform a quick EDA on derived sf data.frames\n\n freq(data = wp_functional,\n     input = 'status_clean')\n\n\n\n\n                 status_clean frequency percentage cumulative_perc\n1                  Functional     45883      87.99           87.99\n2 Functional but needs repair      4579       8.78           96.77\n3   Functional but not in use      1686       3.23          100.00\n\n\n\nfreq(data = wp_nonfunctional,\n     input = 'status_clean')\n\n\n\n\n                      status_clean frequency percentage cumulative_perc\n1                   Non-Functional     29385      91.25           91.25\n2 Non-Functional due to dry season      2403       7.46           98.71\n3         Abandoned/Decommissioned       234       0.73           99.44\n4                        Abandoned       175       0.54           99.98\n5 Non functional due to dry season         7       0.02          100.00\n\n\n\nfreq(data = wp_unknown,\n     input = 'status_clean')\n\n\n\n\n  status_clean frequency percentage cumulative_perc\n1      unknown     10656        100             100\n\n\n\n\nPerforming Point-in-Polygon Count\n\nFind out number of total, functional, non-functional and unknown water points in each LGA.\n\n1) st_intersects() of sf_package (identifies functional water points in each LGA)\n\n\n2) length() (to calculate number of functional water points that fall inside each LGA)\n\nNGA_wp <- NGA %>% \n  mutate(`total_wp` = lengths(\n    st_intersects(NGA, wp_sf_nga))) %>%\n  mutate(`wp_functional` = lengths(\n    st_intersects(NGA, wp_functional))) %>%\n  mutate(`wp_nonfunctional` = lengths(\n    st_intersects(NGA, wp_nonfunctional))) %>%\n  mutate(`wp_unknown` = lengths(\n    st_intersects(NGA, wp_unknown)))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-attributes-by-using-statistical-graphs",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-attributes-by-using-statistical-graphs",
    "title": "In-class Exercise 2: Data Wrangling with R",
    "section": "Visualising attributes by using statistical graphs",
    "text": "Visualising attributes by using statistical graphs\n\nggplot2 package (to reveal distribution of total water points by LGA in histogram)\n\nggplot(data = NGA_wp,\n       aes(x = total_wp)) + \n  geom_histogram(bins=20,\n                 color=\"black\",\n                 fill=\"light blue\") +\n  geom_vline(aes(xintercept=mean(\n    total_wp, na.rm=T)),\n             color=\"red\", \n             linetype=\"dashed\", \n             linewidth=0.8) +\n  ggtitle(\"Distribution of total water points by LGA\") +\n  xlab(\"No. of water points\") +\n  ylab(\"No. of\\nLGAs\") +\n  theme(axis.title.y=element_text(angle = 0))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#saving-the-analytical-data-in-rds-format",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#saving-the-analytical-data-in-rds-format",
    "title": "In-class Exercise 2: Data Wrangling with R",
    "section": "Saving the analytical data in rds format",
    "text": "Saving the analytical data in rds format\n\nTo retain the sf object structure for subsequent analysis, it is recommended to save the sf data.frame into rds format.\n\nwrite_rds() of readr package (to export an sf data.frame into rds format)\n\nwrite_rds(NGA_wp, \"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, tmap)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#deriving-proportion-of-functional-water-points-and-non-functional-water-points",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#deriving-proportion-of-functional-water-points-and-non-functional-water-points",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "Deriving Proportion of Functional Water Points and Non-Functional Water Points",
    "text": "Deriving Proportion of Functional Water Points and Non-Functional Water Points\n\nNGA_wp <- NGA_wp %>%\n  mutate(pct_functional = wp_functional/total_wp) %>%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#plotting-of-map-rate",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#plotting-of-map-rate",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "Plotting of Map Rate",
    "text": "Plotting of Map Rate\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#percentile-map",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#percentile-map",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "Percentile Map",
    "text": "Percentile Map\n\nData Preparation:\n\nStep 1: Exclude records with NA\n\nNGA_wp <- NGA_wp %>%\n  drop_na()\n\n\n\nStep 2: Creating customised classification and extracting values\n\npercent <- c(0,.01,.1,.5,.9,.99,1)\nvar <- NGA_wp[\"pct_functional\"] %>%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#get.var-function",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#get.var-function",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "get.var function",
    "text": "get.var function\n\nget.var <- function(vname,df) {\n  v <- df[vname] %>% \n    st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#a-percentile-mapping-function",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#a-percentile-mapping-function",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "A percentile mapping function",
    "text": "A percentile mapping function\n\npercentmap <- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent <- c(0,.01,.1,.5,.9,.99,1)\n  var <- get.var(vnam, df)\n  bperc <- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"< 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"> 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#test-percentile-mapping-function",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#test-percentile-mapping-function",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "Test percentile mapping function",
    "text": "Test percentile mapping function\n\npercentmap(\"total_wp\", NGA_wp)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#box-map",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#box-map",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "Box Map",
    "text": "Box Map\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\nCreating boxbreaks function\n\nboxbreaks <- function(v,mult=1.5) {\n  qv <- unname(quantile(v))\n  iqr <- qv[4] - qv[2]\n  upfence <- qv[4] + mult * iqr\n  lofence <- qv[2] - mult * iqr\n  # initialize break points vector\n  bb <- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence < qv[1]) {  # no lower outliers\n    bb[1] <- lofence\n    bb[2] <- floor(qv[1])\n  } else {\n    bb[2] <- lofence\n    bb[1] <- qv[1]\n  }\n  if (upfence > qv[5]) { # no upper outliers\n    bb[7] <- upfence\n    bb[6] <- ceiling(qv[5])\n  } else {\n    bb[6] <- upfence\n    bb[7] <- qv[5]\n  }\n  bb[3:5] <- qv[2:4]\n  return(bb)\n}\n\n\n\nCreating get.var function\n\nget.var <- function(vname,df) {\n  v <- df[vname] %>% st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\n\nTest new function\n\nvar <- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#box-map-function",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#box-map-function",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "Box Map Function",
    "text": "Box Map Function\n\nboxmap <- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var <- get.var(vnam,df)\n  bb <- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"< 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"> 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#recode-lgas-with-zero-water-point-into-na",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#recode-lgas-with-zero-water-point-into-na",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "Recode LGAs with zero water point into NA",
    "text": "Recode LGAs with zero water point into NA\n\nNGA_wp <- NGA_wp %>%\n  mutate(wp_functional = na_if(\n    total_wp, total_wp < 0))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#set-tmode-to-plotting",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#set-tmode-to-plotting",
    "title": "In Class Exercise 4: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Set tmode to plotting",
    "text": "Set tmode to plotting"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#set-tmode-to-plotting-1",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#set-tmode-to-plotting-1",
    "title": "In Class Exercise 4: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Set tmode to plotting",
    "text": "Set tmode to plotting"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#converting-sf-data-frames-to-sps-spatial-class",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#converting-sf-data-frames-to-sps-spatial-class",
    "title": "In Class Exercise 4: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Converting sf data frames to sp’s Spatial* class",
    "text": "Converting sf data frames to sp’s Spatial* class\n\n\n\n\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>018989</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>08F73931F4A691F4</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \nmax values  : kml_999,                  <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>829646</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>RAFFLES KIDZ @ PUNGGOL PTE LTD</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>379D017BF244B0FA</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center>"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/data/stores.html",
    "href": "In-class_Ex/In-class_Ex05/data/stores.html",
    "title": "IS415_GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     \n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/data/study_area.html",
    "href": "In-class_Ex/In-class_Ex05/data/study_area.html",
    "title": "IS415_GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5",
    "section": "",
    "text": "Load Packages\n\npacman::p_load(tidyverse, tmap, sf, sfdep)\n\n\n\nImporting Data\n\nstudyArea <- st_read(dsn = \"data\",                      \n                     layer = \"study_area\") %>%         \n  st_transform(crs = 3829)\n\nReading layer `study_area' from data source \n  `C:\\celinderr\\IS415-GAA\\In-class_Ex\\In-class_Ex05\\data' using driver `ESRI Shapefile'\nSimple feature collection with 7 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 121.4836 ymin: 25.00776 xmax: 121.592 ymax: 25.09288\nGeodetic CRS:  TWD97\n\n\n\nstores <- st_read(dsn = \"data\",\n                  layer = \"stores\") %>%\n              st_transform(crs = 3829)\n\nReading layer `stores' from data source \n  `C:\\celinderr\\IS415-GAA\\In-class_Ex\\In-class_Ex05\\data' using driver `ESRI Shapefile'\nSimple feature collection with 1409 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 121.4902 ymin: 25.01257 xmax: 121.5874 ymax: 25.08557\nGeodetic CRS:  TWD97\n\n\n\nstudyArea <- st_read(dsn = \"data\", \n                 layer=\"study_area\") %>%\n  st_transform(crs = 3829)\n\nReading layer `study_area' from data source \n  `C:\\celinderr\\IS415-GAA\\In-class_Ex\\In-class_Ex05\\data' using driver `ESRI Shapefile'\nSimple feature collection with 7 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 121.4836 ymin: 25.00776 xmax: 121.592 ymax: 25.09288\nGeodetic CRS:  TWD97\n\n\n\n\nVisualising the sf layers\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(studyArea) +\n  tm_polygons() +\ntm_shape(stores) +\n  tm_dots(col = \"Name\", \n          size = 0.01,\n          border.col = \"black\", \n          border.lwd = 0.5) + \n  tm_view(set.zoom.limits = c(12,16))\n\n\n\n\n\n\n\n\nLocal Colocation Quotients (LCLQ)\n\nnb <- include_self(\n  st_knn(st_geometry(stores, 6)))\n\nwt <- st_kernel_weights(nb,\n                        stores,\n                        \"gaussian\",\n                        adaptive = TRUE)\n\n\nFamilyMart <- stores %>%\n  filter(Name == \"Family Mart\")\nA <- FamilyMart$Name\n\nSevenEleven <- stores %>%\n  filter(Name == \"7-Eleven\")\nB <- SevenEleven$Name\n\n\nLCLQ <- local_colocation(A, B, nb, wt, 49)\nLCLQ_stores <- cbind(stores, LCLQ)\n\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(studyArea) +\n  tm_polygons() +\ntm_shape(LCLQ_stores)+ \n  tm_dots(col = \"X7.Eleven\",\n             size = 0.01,\n             border.col = \"black\",\n             border.lwd = 0.5) +\n  tm_view(set.zoom.limits = c(12, 16))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-class Exercise 6: Spatial Weights and Applications",
    "section": "",
    "text": "pacman::p_load(sf, tmap , tidyverse, sfdep, dplyr)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#contiguity-neighbours-method",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#contiguity-neighbours-method",
    "title": "In-class Exercise 6: Spatial Weights and Applications",
    "section": "Contiguity Neighbours Method",
    "text": "Contiguity Neighbours Method\n\nst_contiguity() (to derive a contiguity neighcor by using Queen’s method)\n\ncn_queen <- hunan_GDPPC %>%\n    mutate(nb = st_contiguity(geometry),\n                .before = 1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#contiguity-weights-queens-method",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#contiguity-weights-queens-method",
    "title": "In-class Exercise 6: Spatial Weights and Applications",
    "section": "Contiguity weights: Queen’s method",
    "text": "Contiguity weights: Queen’s method\n\nwm_q <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb),\n         .before = 1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "title": "In-class Ex 7",
    "section": "",
    "text": "pacman::p_load(tidyverse,tmap,sf,sfdep)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#contiguity-weights-queens-method",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#contiguity-weights-queens-method",
    "title": "In-class Ex 7",
    "section": "Contiguity weights: Queen’s method",
    "text": "Contiguity weights: Queen’s method\n\nwm_q <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb),\n         .before = 1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#performing-global-morani-permutation-test",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#performing-global-morani-permutation-test",
    "title": "In-class Ex 7",
    "section": "Performing Global Moran’I Permutation Test",
    "text": "Performing Global Moran’I Permutation Test\n\nTo make sure your work is reproducible, if it involves simulation, please make sure you do set.seed(). Everytime it runs, result will vary.\n\nset.seed(1234)\n\n\n\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#mean-and-pysal-should-be-the-ame-in-general",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#mean-and-pysal-should-be-the-ame-in-general",
    "title": "In-class Ex 7",
    "section": "mean and pysal should be the ame in general",
    "text": "mean and pysal should be the ame in general"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#pysal-is-a-python-library-that-does-the-same-thing",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#pysal-is-a-python-library-that-does-the-same-thing",
    "title": "In-class Ex 7",
    "section": "pysal is a python library that does the same thing",
    "text": "pysal is a python library that does the same thing"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#for-take-home-exercise-can-just-stay-with-mean",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#for-take-home-exercise-can-just-stay-with-mean",
    "title": "In-class Ex 7",
    "section": "for take-home exercise, can just stay with mean",
    "text": "for take-home exercise, can just stay with mean"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#for-take-home-not-required-to-do-lisa-only-do-hot-and-cold-spot",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#for-take-home-not-required-to-do-lisa-only-do-hot-and-cold-spot",
    "title": "In-class Ex 7",
    "section": "for take-home, not required to do lisa, only do hot and cold spot",
    "text": "for take-home, not required to do lisa, only do hot and cold spot\n::: # Visualising local Moran’I ::: style=“font-size: 1.5em”}\n\nlisa_sig <- lisa %>%\n  filter(p_ii < 0.05)\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) + \n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n:::"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-p-value-of-local-morani",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-p-value-of-local-morani",
    "title": "In-class Ex 7",
    "section": "Visualising p-value of local Moran’I",
    "text": "Visualising p-value of local Moran’I\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) + \n  tm_fill(\"mean\") +\n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-local-morans-i-and-p-value",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-local-morans-i-and-p-value",
    "title": "In-class Ex 7",
    "section": "Visualising local Moran’s I and p-value",
    "text": "Visualising local Moran’s I and p-value"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#computing-local-morans-i",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#computing-local-morans-i",
    "title": "In-class Ex 7",
    "section": "Computing Local Moran’s I",
    "text": "Computing Local Moran’s I\n\nHCSA <- wm_q %>%\n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wt, nsim = 99),\n      .before = 1) %>%\n    unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 16 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 17\n    gi_star   e_gi     var_gi  p_value p_sim p_fol…¹ skewn…² kurto…³ nb    wt   \n      <dbl>  <dbl>      <dbl>    <dbl> <dbl>   <dbl>   <dbl>   <dbl> <nb>  <lis>\n 1 -0.00567 0.0115 0.00000812  9.95e-1  0.82    0.41   1.03    1.23  <int> <dbl>\n 2 -0.235   0.0110 0.00000581  8.14e-1  1       0.5    0.912   1.05  <int> <dbl>\n 3  0.298   0.0114 0.00000776  7.65e-1  0.7     0.35   0.455  -0.732 <int> <dbl>\n 4  0.145   0.0121 0.0000111   8.84e-1  0.64    0.32   0.900   0.726 <int> <dbl>\n 5  0.356   0.0113 0.0000119   7.21e-1  0.64    0.32   1.08    1.31  <int> <dbl>\n 6 -0.480   0.0116 0.00000706  6.31e-1  0.82    0.41   0.364  -0.676 <int> <dbl>\n 7  3.66    0.0116 0.00000825  2.47e-4  0.02    0.01   0.909   0.664 <int> <dbl>\n 8  2.14    0.0116 0.00000714  3.26e-2  0.16    0.08   1.13    1.48  <int> <dbl>\n 9  4.55    0.0113 0.00000656  5.28e-6  0.02    0.01   1.36    4.14  <int> <dbl>\n10  1.61    0.0109 0.00000341  1.08e-1  0.18    0.09   0.269  -0.396 <int> <dbl>\n# … with 78 more rows, 7 more variables: NAME_2 <chr>, ID_3 <int>,\n#   NAME_3 <chr>, ENGTYPE_3 <chr>, County <chr>, GDPPC <dbl>,\n#   geometry <POLYGON [°]>, and abbreviated variable names ¹​p_folded_sim,\n#   ²​skewness, ³​kurtosis"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-gi",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-gi",
    "title": "In-class Ex 7",
    "section": "Visualising Gi",
    "text": "Visualising Gi\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n#view will be interactive, plot will be fixed\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") +\n  tm_borders(alpha=0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-p-value-of-hcsa",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-p-value-of-hcsa",
    "title": "In-class Ex 7",
    "section": "Visualising p-value of HCSA",
    "text": "Visualising p-value of HCSA\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nPart 3 of take-home exercise\nhow to perform emerging hot and cold spot analysis\n1) they are all in same csv structure but different files, so you need to bring csv file in, consolidate them into a single csv folder. format: (Year | County | GDPPC)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07_EHSCA.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07_EHSCA.html",
    "title": "In Class 7: Emerging Cold and Hot Spots",
    "section": "",
    "text": "pacman:: p_load(tidyverse, sf, sfdep, plotly, tmap, zoo, plyr)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07_EHSCA.html#import-data",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07_EHSCA.html#import-data",
    "title": "In Class 7: Emerging Cold and Hot Spots",
    "section": "Import Data",
    "text": "Import Data\n\nhunan <- st_read(\"data/geospatial\",\n            layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\celinderr\\IS415-GAA\\In-class_Ex\\In-class_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nGDPPC <- read_csv(\"./data/aspatial/Hunan_GDPPC.csv\")\n\nRows: 1496 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): County\ndbl (2): Year, GDPPC\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nhunan_GDPPC <- left_join(GDPPC, hunan)%>%\n  select(1:4, 7, 10)\n\nJoining, by = \"County\""
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07_EHSCA.html#creating-a-time-series-cube",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07_EHSCA.html#creating-a-time-series-cube",
    "title": "In Class 7: Emerging Cold and Hot Spots",
    "section": "Creating a Time Series Cube",
    "text": "Creating a Time Series Cube\n\nGDPPC_st <- spacetime(GDPPC, hunan,\n                      .loc_col = \"County\",\n                      .time_col = \"Year\")\nGDPPC_st\n\nspacetime ────\n\n\nContext:`data`\n\n\n88 locations `County`\n\n\n17 time periods `Year`\n\n\n── data context ────────────────────────────────────────────────────────────────\n\n\n# A tibble: 1,496 × 3\n    Year County    GDPPC\n * <dbl> <chr>     <dbl>\n 1  2005 Longshan   3469\n 2  2005 Changsha  24612\n 3  2005 Wangcheng 14659\n 4  2005 Ningxiang 11687\n 5  2005 Liuyang   13406\n 6  2005 Zhuzhou    8546\n 7  2005 You       10944\n 8  2005 Chaling    8040\n 9  2005 Yanling    7383\n10  2005 Liling    11688\n# … with 1,486 more rows\n\n\n:::\n\nGDPPC_nb <- GDPPC_st %>%\n  activate(\"geometry\") %>%\n  mutate(\n    nb = include_self(st_contiguity(geometry)),\n    wt = st_weights(nb)\n        ) %>%\n  set_nbs(\"nb\") %>%\n  set_wts(\"wt\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07_EHSCA.html#computing-gi",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07_EHSCA.html#computing-gi",
    "title": "In Class 7: Emerging Cold and Hot Spots",
    "section": "Computing Gi",
    "text": "Computing Gi\n\ngi_star <- GDPPC_nb %>%\n  group_by(Year) %>%\n  mutate(gi_star = local_gstar_perm(\n      GDPPC, nb, wt, nsim = 99)) %>%\n  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html",
    "title": "Hands-on 8; Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "pacman::p_load(olsrr, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#updating-crs-information",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#updating-crs-information",
    "title": "Hands-on 8; Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Updating CRS information",
    "text": "Updating CRS information\n\nmpsz_svy21 <- st_transform(mpsz, 3414)\n\n\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#reveal-extent-of-mpsz_svy21-using-st_bbox-of-sf-package",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#reveal-extent-of-mpsz_svy21-using-st_bbox-of-sf-package",
    "title": "Hands-on 8; Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Reveal extent of mpsz_svy21 using st_bbox of sf package",
    "text": "Reveal extent of mpsz_svy21 using st_bbox of sf package\n\nst_bbox(mpsz_svy21)\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#aspatial-data-wrangling",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#aspatial-data-wrangling",
    "title": "Hands-on 8; Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Aspatial Data Wrangling",
    "text": "Aspatial Data Wrangling\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nRows: 1436 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (23): LATITUDE, LONGITUDE, POSTCODE, SELLING_PRICE, AREA_SQM, AGE, PROX_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nDisplay data structure of it\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             <dbl> 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            <dbl> 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             <dbl> 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\n\nSee data in x-coord column\n\nhead(condo_resale$LONGITUDE)\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\n\n\nSee data in y-coord column\n\nhead(condo_resale$LATITUDE)\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\n\n\nDisplay summary statistics with summary() of base R\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#convert-aspatial-data-into-sf-object",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#convert-aspatial-data-into-sf-object",
    "title": "Hands-on 8; Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Convert aspatial data into sf object",
    "text": "Convert aspatial data into sf object\n\ncondo_resale.sf <- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %>%\n  st_transform(crs=3414)\n\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLI…¹ AREA_…²   AGE PROX_…³ PROX_…⁴ PROX_…⁵ PROX_…⁶ PROX_…⁷ PROX_…⁸\n     <dbl>   <dbl>   <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1   118635 3000000     309    30    7.94   0.166   2.52     6.62   1.77   0.0584\n2   288420 3880000     290    32    6.61   0.280   1.93     7.51   0.545  0.616 \n3   267833 3325000     248    33    6.90   0.429   0.502    6.46   0.378  0.141 \n4   258380 4250000     127     7    4.04   0.395   1.99     4.91   1.68   0.382 \n5   467169 1400000     145    28   11.8    0.119   1.12     6.41   0.565  0.461 \n6   466472 1320000     139    22   10.3    0.125   0.789    5.09   0.781  0.0994\n# … with 12 more variables: PROX_MRT <dbl>, PROX_PARK <dbl>,\n#   PROX_PRIMARY_SCH <dbl>, PROX_TOP_PRIMARY_SCH <dbl>,\n#   PROX_SHOPPING_MALL <dbl>, PROX_SUPERMARKET <dbl>, PROX_BUS_STOP <dbl>,\n#   NO_Of_UNITS <dbl>, FAMILY_FRIENDLY <dbl>, FREEHOLD <dbl>,\n#   LEASEHOLD_99YR <dbl>, geometry <POINT [m]>, and abbreviated variable names\n#   ¹​SELLING_PRICE, ²​AREA_SQM, ³​PROX_CBD, ⁴​PROX_CHILDCARE, ⁵​PROX_ELDERLYCARE,\n#   ⁶​PROX_URA_GROWTH_AREA, ⁷​PROX_HAWKER_MARKET, ⁸​PROX_KINDERGARTEN"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#eda-using-statistics-graphics",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#eda-using-statistics-graphics",
    "title": "Hands-on 8; Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "EDA using statistics graphics",
    "text": "EDA using statistics graphics\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\ncondo_resale.sf <- condo_resale.sf %>%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#multiple-histogram-plots-distribution-of-variables",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#multiple-histogram-plots-distribution-of-variables",
    "title": "Hands-on 8; Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Multiple Histogram Plots distribution of variables",
    "text": "Multiple Histogram Plots distribution of variables\n\nAREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex11/data/geospatial/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex11/data/geospatial/MPSZ-2019.html",
    "title": "IS415_GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "Welcome to IS415 Geospatial Analytics and Applications;\nThis is my course website for my exercises."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "The following data sets will be used in the analysis:\n\n\n\nWater Point Data | Format: csv | WPdx Data Repository\n\n\n\nState boundary GIS data of Nigeria | Format: Shapefile | geoBoundaries"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-nga-dataset",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-nga-dataset",
    "title": "Take Home Exercise 1",
    "section": "The NGA dataset",
    "text": "The NGA dataset\n\nNGA <- st_read(\"data/geospatial/\",\n               layer = \"nga_admbnda_adm2_osgof_20190417\") %>%\n  st_transform(crs = 26392)\n\nReading layer `nga_admbnda_adm2_osgof_20190417' from data source \n  `C:\\celinderr\\IS415-GAA\\Take-home_Ex\\Take-home_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-water-point-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-water-point-data",
    "title": "Take Home Exercise 1",
    "section": "The Water Point data",
    "text": "The Water Point data\n\nwp_nga <- read_csv(\"./data/aspatial/WPdx.csv\") %>%\n  filter(`#clean_country_name` == \"Nigeria\")\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n\n\nRows: 406566 Columns: 70\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (43): #source, #report_date, #status_id, #water_source_clean, #water_sou...\ndbl (23): row_id, #lat_deg, #lon_deg, #install_year, #fecal_coliform_value, ...\nlgl  (4): #rehab_year, #rehabilitator, is_urban, latest_record\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#excluding-redundant-fields",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#excluding-redundant-fields",
    "title": "Take Home Exercise 1",
    "section": "Excluding redundant fields",
    "text": "Excluding redundant fields\n\nNGA <- NGA %>%\n  select(c(3:4, 8:9))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#checking-for-duplicate",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#checking-for-duplicate",
    "title": "Take Home Exercise 1",
    "section": "Checking for duplicate",
    "text": "Checking for duplicate\n\nNGA$ADM2_EN[duplicated(NGA$ADM2_EN)==TRUE]\n\n[1] \"Bassa\"    \"Ifelodun\" \"Irepodun\" \"Nasarawa\" \"Obi\"      \"Surulere\"\n\n\n\nCorrecting the duplicates\n\nNGA$ADM2_EN[94] <- \"Bassa, Kogi\"\nNGA$ADM2_EN[95] <- \"Bassa, Plateau\"\nNGA$ADM2_EN[304] <- \"Ifelodun, Kwara\"\nNGA$ADM2_EN[305] <- \"Ifelodun, Osun\"\nNGA$ADM2_EN[355] <- \"Irepodun, Kwara\"\nNGA$ADM2_EN[356] <- \"Irepodun, Osun\"\nNGA$ADM2_EN[519] <- \"Nasarawa, Kano\"\nNGA$ADM2_EN[520] <- \"Nasarawa, Nasarawa\"\nNGA$ADM2_EN[546] <- \"Obi, Benue\"\nNGA$ADM2_EN[547] <- \"Obi, Nasarawa\"\nNGA$ADM2_EN[693] <- \"Surulere, Lagos\"\nNGA$ADM2_EN[694] <- \"Surulere, Oyo\"\n\n\n\nCheck again\n\nNGA$ADM2_EN[duplicated(NGA$ADM2_EN)==TRUE]\n\ncharacter(0)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#filter-only-osun-state-is-needed",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#filter-only-osun-state-is-needed",
    "title": "Take Home Exercise 1",
    "section": "Filter only Osun state is needed",
    "text": "Filter only Osun state is needed\n\nNGA<-NGA %>%filter(`ADM1_EN` == \"Osun\")\n\n\nNote: NGA data minimized to only 30 observations (Osun state)\n\nwp_nga <- wp_nga %>%filter(`#clean_adm1` == \"Osun\")\n\n\n\nNote: Water Point data also minimized to only 5745 observations (Osun state)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#convert-water-point-data-into-sf-point-features",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#convert-water-point-data-into-sf-point-features",
    "title": "Take Home Exercise 1",
    "section": "Convert water point data into sf point features",
    "text": "Convert water point data into sf point features\n\nStep 1: Convert the wkt field into sfc field by using st_as_sfc() data type\n\nwp_nga$Geometry = st_as_sfc(wp_nga$`New Georeferenced Column`)\nwp_nga\n\n# A tibble: 5,557 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429123 GRID3             8.02    5.06 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2  70566 Federal Minis…    7.32    4.79 05/11/… No      Protec… Well    Mechan…\n 3  70578 Federal Minis…    7.76    4.56 05/11/… No      Boreho… Well    Mechan…\n 4  66401 Federal Minis…    8.03    4.64 04/30/… No      Boreho… Well    Mechan…\n 5 422190 GRID3             7.87    4.88 08/29/… Unknown <NA>    <NA>    Tapsta…\n 6 422064 GRID3             7.7     4.89 08/29/… Unknown <NA>    <NA>    Tapsta…\n 7  65607 Federal Minis…    7.89    4.71 05/12/… No      Boreho… Well    Mechan…\n 8  68989 Federal Minis…    7.51    4.27 05/07/… No      Boreho… Well    <NA>   \n 9  67708 Federal Minis…    7.48    4.35 04/29/… Yes     Boreho… Well    Mechan…\n10  66419 Federal Minis…    7.63    4.50 05/08/… Yes     Boreho… Well    Hand P…\n# … with 5,547 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\n\n\nStep 2: Convert the wkt field into sfc field by using st_as_sfc() data type\n\nwp_sf <- st_sf(wp_nga, crs=4326)\n\n\n\nTransform into Nigeria projected coordinate system (from WGS84)\n\nwp_sf <- wp_sf %>%st_transform(crs = 26392)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extracting-water-point-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extracting-water-point-data",
    "title": "Take Home Exercise 1",
    "section": "Extracting Water Point Data",
    "text": "Extracting Water Point Data\n\nExtracting functional water point\n\nwp_functional <- wp_sf_nga %>%\n  filter(status_clean %in%\n           c(\"Functional\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\n\n\nExtracting non-functional water point\n\nwp_nonfunctional <- wp_sf_nga %>%\n  filter(status_clean %in%\n           c(\"Abandoned/Decommissioned\",\n             \"Abandoned\",\n             \"Non-Functional due to dry season\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\"))\n\n\n\nExtracting water point with unknown status\n\nwp_unknown <- wp_sf_nga %>%\n  filter(status_clean == \"unknown\")\n\n\n\nPerforming Point-in-Polygon Count\n\nNGA_wp <- NGA %>% \n  mutate(`total_wp` = lengths(\n    st_intersects(NGA, wp_sf_nga))) %>%\n  mutate(`wp_functional` = lengths(\n    st_intersects(NGA, wp_functional))) %>%\n  mutate(`wp_nonfunctional` = lengths(\n    st_intersects(NGA, wp_nonfunctional))) %>%\n  mutate(`wp_unknown` = lengths(\n    st_intersects(NGA, wp_unknown)))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-sf-data-frames-to-sps-spatial-class",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-sf-data-frames-to-sps-spatial-class",
    "title": "Take Home Exercise 1",
    "section": "Converting sf data frames to sp’s Spatial* class",
    "text": "Converting sf data frames to sp’s Spatial* class\n\nNGA_spatial <- as_Spatial(NGA)\nfunctional_wp_spatial <- as_Spatial(wp_functional)\nnon_functional_wp_spatial <- as_Spatial(wp_nonfunctional)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-the-spatial-class-into-generic-sp-format",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-the-spatial-class-into-generic-sp-format",
    "title": "Take Home Exercise 1",
    "section": "Converting the Spatial* class into generic sp format",
    "text": "Converting the Spatial* class into generic sp format\n\nfunctional_wp_sp <- as(functional_wp_spatial, \"SpatialPoints\")\nnon_functional_wp_sp <- as(non_functional_wp_spatial, \"SpatialPoints\")\nNGA_sp <- as(NGA_spatial, \"SpatialPolygons\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "Take Home Exercise 1",
    "section": "Converting the generic sp format into spatstat’s ppp format",
    "text": "Converting the generic sp format into spatstat’s ppp format\n\nfunctional_wp_ppp <- as(functional_wp_sp, \"ppp\")\nnon_functional_wp_ppp <- as(non_functional_wp_sp, \"ppp\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#lets-see-the-summary-of-the-newly-created-ppp-objects",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#lets-see-the-summary-of-the-newly-created-ppp-objects",
    "title": "Take Home Exercise 1",
    "section": "Let’s see the summary of the newly created ppp objects",
    "text": "Let’s see the summary of the newly created ppp objects\n\nsummary(functional_wp_ppp)\n\nPlanar point pattern:  2630 points\nAverage intensity 2.151545e-07 points per square unit\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nWindow: rectangle = [177285.9, 290750.96] x [343128.1, 450859.7] units\n                    (113500 x 107700 units)\nWindow area = 12223800000 square units\n\n\n\nsummary(non_functional_wp_ppp)\n\nPlanar point pattern:  2179 points\nAverage intensity 1.787766e-07 points per square unit\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nWindow: rectangle = [180538.96, 290616] x [340054.1, 450780.1] units\n                    (110100 x 110700 units)\nWindow area = 12188400000 square units\n\n\n#3# Checking for duplicates\n\nany(duplicated(functional_wp_ppp))\n\n[1] FALSE\n\nany(duplicated(non_functional_wp_ppp))\n\n[1] FALSE\n\n\n` ## Create owin object\n\nNGA_owin <- as(NGA_sp, \"owin\")\nplot(NGA_owin)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#combine-point-events-object-and-owin-object",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#combine-point-events-object-and-owin-object",
    "title": "Take Home Exercise 1",
    "section": "Combine point events object and owin object",
    "text": "Combine point events object and owin object\n\nfunctional_wp_NGA_ppp = functional_wp_ppp[NGA_owin]\nnon_functional_wp_NGA_ppp = non_functional_wp_ppp[NGA_owin]"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#point-map-of-functional-water-points-in-osun",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#point-map-of-functional-water-points-in-osun",
    "title": "Take Home Exercise 1",
    "section": "Point Map of functional water points in Osun",
    "text": "Point Map of functional water points in Osun\n\nplot(functional_wp_NGA_ppp)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#kernel-density-estimation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#kernel-density-estimation",
    "title": "Take Home Exercise 1",
    "section": "Kernel Density Estimation",
    "text": "Kernel Density Estimation\n\nfunctional_wp_NGA_kde_bw <- density(functional_wp_NGA_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\n\n\nnon_functional_wp_NGA_kde_bw <- density(non_functional_wp_NGA_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#plot-kernel-density-maps",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#plot-kernel-density-maps",
    "title": "Take Home Exercise 1",
    "section": "Plot Kernel Density Maps",
    "text": "Plot Kernel Density Maps\n\nFunctional water points\n\nplot(functional_wp_NGA_kde_bw)\n\n\n\n\n\n\nNon-functional water points\n\nplot(non_functional_wp_NGA_kde_bw)\n\n\n\n\n\nNote: Density values way too small, required to change bandwidth"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#retrieve-bandwidth",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#retrieve-bandwidth",
    "title": "Take Home Exercise 1",
    "section": "Retrieve bandwidth",
    "text": "Retrieve bandwidth\n\nbw <- bw.diggle(functional_wp_NGA_ppp)\nbw\n\n   sigma \n252.1687"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#rescale-kde-values-from-meter-to-kilometer",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#rescale-kde-values-from-meter-to-kilometer",
    "title": "Take Home Exercise 1",
    "section": "Rescale KDE values from meter to kilometer",
    "text": "Rescale KDE values from meter to kilometer\n\nfunctional_wp_NGA_ppp.km <- rescale(functional_wp_NGA_ppp, 1000, \"km\")\nnon_functional_wp_NGA_ppp.km <- rescale(non_functional_wp_NGA_ppp, 1000, \"km\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#assigning-projection-systems",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#assigning-projection-systems",
    "title": "Take Home Exercise 1",
    "section": "Assigning projection systems",
    "text": "Assigning projection systems\n\nprojection(functional_kde_wp_NGA_bw_raster) <- CRS(\"+init=EPSG:26392\")\nprojection(non_functional_kde_wp_NGA_bw_raster) <- CRS(\"+init=EPSG:26392\")\nfunctional_kde_wp_NGA_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -5.092436e-15, 25.49435  (min, max)\n\nnon_functional_kde_wp_NGA_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -3.925434e-15, 20.49412  (min, max)\n\n\n\nNote: crs propert now assigned"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-tm_basemapopenstreetmap-tm_shapegridded_kde_functional_wp_nga.bw-tm_rasterv-tm_layoutlegend.position-cright-bottom-frame-false",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-tm_basemapopenstreetmap-tm_shapegridded_kde_functional_wp_nga.bw-tm_rasterv-tm_layoutlegend.position-cright-bottom-frame-false",
    "title": "Take Home Exercise 1",
    "section": "{r} tm_basemap(\"OpenStreetMap\")  tm_shape(gridded_kde_functional_wp_NGA.bw) +    tm_raster(\"v\") +   tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)",
    "text": "{r} tm_basemap(\"OpenStreetMap\")  tm_shape(gridded_kde_functional_wp_NGA.bw) +    tm_raster(\"v\") +   tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-tm_shapenon_functional_kde_wp_nga_bw_raster-tm_rasterv-tm_layoutlegend.position-cright-bottom-frame-false",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-tm_shapenon_functional_kde_wp_nga_bw_raster-tm_rasterv-tm_layoutlegend.position-cright-bottom-frame-false",
    "title": "Take Home Exercise 1",
    "section": "{r} tm_shape(non_functional_kde_wp_NGA_bw_raster) +    tm_raster(\"v\") +   tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)",
    "text": "{r} tm_shape(non_functional_kde_wp_NGA_bw_raster) +    tm_raster(\"v\") +   tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#answer",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#answer",
    "title": "Take Home Exercise 1",
    "section": "Answer:",
    "text": "Answer:\n\nThe spatial patterns revealed shows that there are highly densed water point areas with non functional water points.\n\n\nKernel density maps can provide a more comprehensive and informative view of spatial data than point maps, especially when dealing with complex and dense data sets.\n\n\nPattern recognition: Kernel density maps can reveal underlying patterns in the spatial distribution of data points that may not be immediately apparent from a point map. For example, a kernel density map can show areas of high or low density that are not immediately apparent from individual data points.\n\n\nSmoothing: Kernel density maps provide a smoother representation of the spatial distribution of data points, as they are based on a continuous surface that estimates the density of data points in a given area.\n\n\nHandling Overplotting: Point maps can become cluttered and difficult to interpret when there are many data points in a small area, which is known as overplotting. Kernel density maps can handle overplotting by estimating the density of data points in a given area, rather than plotting individual points.\n\n\nCustomization: Kernel density maps can be customized to suit different data sets and analysis goals, as the shape and size of the kernel can be adjusted to suit different distributions and scales."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#l-function-estimation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#l-function-estimation",
    "title": "Take Home Exercise 1",
    "section": "L-function estimation",
    "text": "L-function estimation"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-l_osun_functional-lestfunctional_wp_nga_ppp.km-correctionc-ripley-plotl_osun_functional-.--r-r-ylab-ld-r-xlab-dm",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-l_osun_functional-lestfunctional_wp_nga_ppp.km-correctionc-ripley-plotl_osun_functional-.--r-r-ylab-ld-r-xlab-dm",
    "title": "Take Home Exercise 1",
    "section": "{r} L_osun_functional = Lest(functional_wp_NGA_ppp.km, correctionc = \"Ripley\") plot(L_osun_functional, . -r ~ r,       ylab= \"L(d)-r\", xlab = \"d(m)\")",
    "text": "{r} L_osun_functional = Lest(functional_wp_NGA_ppp.km, correctionc = \"Ripley\") plot(L_osun_functional, . -r ~ r,       ylab= \"L(d)-r\", xlab = \"d(m)\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-l_osun_non_functional-lestnon_functional_wp_nga_ppp.km-correctionc-ripley-plotl_osun_non_functional-.--r-r-ylab-ld-r-xlab-dm",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-l_osun_non_functional-lestnon_functional_wp_nga_ppp.km-correctionc-ripley-plotl_osun_non_functional-.--r-r-ylab-ld-r-xlab-dm",
    "title": "Take Home Exercise 1",
    "section": "{r} L_osun_non_functional = Lest(non_functional_wp_NGA_ppp.km, correctionc = \"Ripley\") plot(L_osun_non_functional, . -r ~ r,       ylab= \"L(d)-r\", xlab = \"d(m)\")",
    "text": "{r} L_osun_non_functional = Lest(non_functional_wp_NGA_ppp.km, correctionc = \"Ripley\") plot(L_osun_non_functional, . -r ~ r,       ylab= \"L(d)-r\", xlab = \"d(m)\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-complete-spatial-randomness-test",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-complete-spatial-randomness-test",
    "title": "Take Home Exercise 1",
    "section": "Performing Complete Spatial Randomness Test",
    "text": "Performing Complete Spatial Randomness Test"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#h0-the-distribution-of-functional-water-points-in-osun-are-randomly-distributed.",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#h0-the-distribution-of-functional-water-points-in-osun-are-randomly-distributed.",
    "title": "Take Home Exercise 1",
    "section": "H0: The distribution of functional water points in Osun are randomly distributed.",
    "text": "H0: The distribution of functional water points in Osun are randomly distributed."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#h1-the-distribution-of-functaional-water-points-in-osun-are-not-randomly-distributed.",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#h1-the-distribution-of-functaional-water-points-in-osun-are-not-randomly-distributed.",
    "title": "Take Home Exercise 1",
    "section": "H1: The distribution of functaional water points in Osun are not randomly distributed.",
    "text": "H1: The distribution of functaional water points in Osun are not randomly distributed."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-null-hypothesis-will-be-rejected-if-p-value-is-smaller-than-alpha-value-of-0.001.",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-null-hypothesis-will-be-rejected-if-p-value-is-smaller-than-alpha-value-of-0.001.",
    "title": "Take Home Exercise 1",
    "section": "The null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.",
    "text": "The null hypothesis will be rejected if p-value is smaller than alpha value of 0.001."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#hypothesis-testing-functional-water-points",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#hypothesis-testing-functional-water-points",
    "title": "Take Home Exercise 1",
    "section": "Hypothesis Testing (Functional Water Points)",
    "text": "Hypothesis Testing (Functional Water Points)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-l_osun_functional---envelopefunctional_wp_nga_ppp.km-lest-nsim-39-rank-1-glocaltrue",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-l_osun_functional---envelopefunctional_wp_nga_ppp.km-lest-nsim-39-rank-1-glocaltrue",
    "title": "Take Home Exercise 1",
    "section": "{r} L_osun_functional <- envelope(functional_wp_NGA_ppp.km, Lest, nsim = 39, rank = 1, glocal=TRUE)",
    "text": "{r} L_osun_functional <- envelope(functional_wp_NGA_ppp.km, Lest, nsim = 39, rank = 1, glocal=TRUE)\n#{r} plot(L_osun_functional, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#h0-the-distribution-of-non-functional-water-points-in-osun-are-randomly-distributed.",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#h0-the-distribution-of-non-functional-water-points-in-osun-are-randomly-distributed.",
    "title": "Take Home Exercise 1",
    "section": "H0: The distribution of non-functional water points in Osun are randomly distributed.",
    "text": "H0: The distribution of non-functional water points in Osun are randomly distributed."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#h1-the-distribution-of-non-functional-water-points-in-osun-are-not-randomly-distributed.",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#h1-the-distribution-of-non-functional-water-points-in-osun-are-not-randomly-distributed.",
    "title": "Take Home Exercise 1",
    "section": "H1: The distribution of non-functional water points in Osun are not randomly distributed.",
    "text": "H1: The distribution of non-functional water points in Osun are not randomly distributed."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-null-hypothesis-will-be-rejected-if-p-value-is-smaller-than-alpha-value-of-0.001.-1",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-null-hypothesis-will-be-rejected-if-p-value-is-smaller-than-alpha-value-of-0.001.-1",
    "title": "Take Home Exercise 1",
    "section": "The null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.",
    "text": "The null hypothesis will be rejected if p-value is smaller than alpha value of 0.001."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#hypothesis-testing-non-functional-water-points",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#hypothesis-testing-non-functional-water-points",
    "title": "Take Home Exercise 1",
    "section": "Hypothesis Testing (Non Functional Water Points)",
    "text": "Hypothesis Testing (Non Functional Water Points)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-l_osun_non_functional---envelopenon_functional_wp_nga_ppp.km-lest-nsim-39-rank-1-glocaltrue",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-l_osun_non_functional---envelopenon_functional_wp_nga_ppp.km-lest-nsim-39-rank-1-glocaltrue",
    "title": "Take Home Exercise 1",
    "section": "{r} L_osun_non_functional <- envelope(non_functional_wp_NGA_ppp.km, Lest, nsim = 39, rank = 1, glocal=TRUE)",
    "text": "{r} L_osun_non_functional <- envelope(non_functional_wp_NGA_ppp.km, Lest, nsim = 39, rank = 1, glocal=TRUE)\n##{r} plot(L_osun_non_functional, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#answer-1",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#answer-1",
    "title": "Take Home Exercise 1",
    "section": "Answer:",
    "text": "Answer:"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#since-the-p-value-is-smaller-than-the-alpha-value-the-null-hypotheses-will-be-rejected-in-both-testing.-from-the-analysis-it-is-also-observed-that-many-of-the-observations-lie-outside-of-the-envelope-which-proves-that-there-is-enough-statistical-evidence-to-reject-the-null-hypotheses.",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#since-the-p-value-is-smaller-than-the-alpha-value-the-null-hypotheses-will-be-rejected-in-both-testing.-from-the-analysis-it-is-also-observed-that-many-of-the-observations-lie-outside-of-the-envelope-which-proves-that-there-is-enough-statistical-evidence-to-reject-the-null-hypotheses.",
    "title": "Take Home Exercise 1",
    "section": "Since the p-value is smaller than the alpha value, the null hypotheses will be rejected in both testing. From the analysis, it is also observed that many of the observations lie outside of the envelope, which proves that there is enough statistical evidence to reject the null hypotheses.",
    "text": "Since the p-value is smaller than the alpha value, the null hypotheses will be rejected in both testing. From the analysis, it is also observed that many of the observations lie outside of the envelope, which proves that there is enough statistical evidence to reject the null hypotheses."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#hence-it-is-inferred-that-both-functional-and-non-functional-water-points-are-not-randomly-distributed.",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#hence-it-is-inferred-that-both-functional-and-non-functional-water-points-are-not-randomly-distributed.",
    "title": "Take Home Exercise 1",
    "section": "Hence, it is inferred that both functional and non-functional water points are not randomly distributed.",
    "text": "Hence, it is inferred that both functional and non-functional water points are not randomly distributed."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualising-the-sf-layers",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualising-the-sf-layers",
    "title": "Take Home Exercise 1",
    "section": "Visualising the sf layers",
    "text": "Visualising the sf layers\n##{r} tmap_mode(\"view\") tm_shape(wp_functional) +   tm_polygons() + tm_shape(wp_nonfunctional) +   tm_dots(col = \"Name\",            size = 0.01,           border.col = \"black\",            border.lwd = 0.5) +    tm_view(set.zoom.limits = c(12,16))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#plot-lclq-values",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#plot-lclq-values",
    "title": "Take Home Exercise 1",
    "section": "Plot LCLQ values",
    "text": "Plot LCLQ values"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-tmap_modeview-tm_shapewp_nga-tm_polygons-tm_shapelclq_wp-tm_dotscol-water-points-size-0.01-border.col-black-border.lwd-0.5-tm_viewset.zoom.limits-c12-16",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-tmap_modeview-tm_shapewp_nga-tm_polygons-tm_shapelclq_wp-tm_dotscol-water-points-size-0.01-border.col-black-border.lwd-0.5-tm_viewset.zoom.limits-c12-16",
    "title": "Take Home Exercise 1",
    "section": "{r} tmap_mode(\"view\") tm_shape(wp_nga) +   tm_polygons() + tm_shape(LCLQ_wp)+    tm_dots(col = \"Water Points\",              size = 0.01,              border.col = \"black\",              border.lwd = 0.5) +   tm_view(set.zoom.limits = c(12, 16))",
    "text": "{r} tmap_mode(\"view\") tm_shape(wp_nga) +   tm_polygons() + tm_shape(LCLQ_wp)+    tm_dots(col = \"Water Points\",              size = 0.01,              border.col = \"black\",              border.lwd = 0.5) +   tm_view(set.zoom.limits = c(12, 16))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-complete-spatial-randomness-test-1",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#performing-complete-spatial-randomness-test-1",
    "title": "Take Home Exercise 1",
    "section": "Performing Complete Spatial Randomness Test",
    "text": "Performing Complete Spatial Randomness Test"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#h0-the-distribution-of-water-points-in-osun-are-randomly-distributed-from-each-other.",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#h0-the-distribution-of-water-points-in-osun-are-randomly-distributed-from-each-other.",
    "title": "Take Home Exercise 1",
    "section": "H0: The distribution of water points in Osun are randomly distributed from each other.",
    "text": "H0: The distribution of water points in Osun are randomly distributed from each other."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#h1-the-distribution-of-water-points-in-osun-are-not-randomly-distributed-from-each-other.",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#h1-the-distribution-of-water-points-in-osun-are-not-randomly-distributed-from-each-other.",
    "title": "Take Home Exercise 1",
    "section": "H1: The distribution of water points in Osun are not randomly distributed from each other.",
    "text": "H1: The distribution of water points in Osun are not randomly distributed from each other."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-null-hypothesis-will-be-rejected-if-p-value-is-smaller-than-alpha-value-of-0.001.-2",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-null-hypothesis-will-be-rejected-if-p-value-is-smaller-than-alpha-value-of-0.001.-2",
    "title": "Take Home Exercise 1",
    "section": "The null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.",
    "text": "The null hypothesis will be rejected if p-value is smaller than alpha value of 0.001."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-l_osun_lclq-lestlclq_wp-correctionc-ripley-plotl_osun_lclq-.--r-r-ylab-ld-r-xlab-dm",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-l_osun_lclq-lestlclq_wp-correctionc-ripley-plotl_osun_lclq-.--r-r-ylab-ld-r-xlab-dm",
    "title": "Take Home Exercise 1",
    "section": "{r} L_osun_LCLQ = Lest(LCLQ_wp, correctionc = \"Ripley\") plot(L_osun_LCLQ, . -r ~ r,       ylab= \"L(d)-r\", xlab = \"d(m)\")",
    "text": "{r} L_osun_LCLQ = Lest(LCLQ_wp, correctionc = \"Ripley\") plot(L_osun_LCLQ, . -r ~ r,       ylab= \"L(d)-r\", xlab = \"d(m)\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-l_osun_lclq---envelopelclq_wp-lest-nsim-39-rank-1-glocaltrue",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-l_osun_lclq---envelopelclq_wp-lest-nsim-39-rank-1-glocaltrue",
    "title": "Take Home Exercise 1",
    "section": "{r} L_osun_LCLQ <- envelope(LCLQ_wp, Lest, nsim = 39, rank = 1, glocal=TRUE)",
    "text": "{r} L_osun_LCLQ <- envelope(LCLQ_wp, Lest, nsim = 39, rank = 1, glocal=TRUE)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-plotl_osun_lclq-.---r-r-xlabd-ylabld-r",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#r-plotl_osun_lclq-.---r-r-xlabd-ylabld-r",
    "title": "Take Home Exercise 1",
    "section": "{r} plot(L_osun_LCLQ, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")",
    "text": "{r} plot(L_osun_LCLQ, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#since-the-line-of-the-chart-of-corelation-between-functional-and-non-functional-water-points-majorly-fall-outside-the-envelope-the-null-hypothesis-is-rejected.-the-distribution-of-water-points-are-not-distributed-randomly-in-osun.",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#since-the-line-of-the-chart-of-corelation-between-functional-and-non-functional-water-points-majorly-fall-outside-the-envelope-the-null-hypothesis-is-rejected.-the-distribution-of-water-points-are-not-distributed-randomly-in-osun.",
    "title": "Take Home Exercise 1",
    "section": "Since the line of the chart of corelation between functional and non-functional water points majorly fall outside the envelope, the null hypothesis is rejected. The distribution of water points are not distributed randomly in Osun.",
    "text": "Since the line of the chart of corelation between functional and non-functional water points majorly fall outside the envelope, the null hypothesis is rejected. The distribution of water points are not distributed randomly in Osun."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aspatial",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aspatial",
    "title": "Take Home Exercise 2",
    "section": "Aspatial",
    "text": "Aspatial\n\nData Vaksinasi Berbasis Kelurahan (01 Juli 2021) | Format: .xlsx | Riwayat File Vaksinasi DKI Jakarta"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#geospatial",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#geospatial",
    "title": "Take Home Exercise 2",
    "section": "Geospatial",
    "text": "Geospatial\n\nBATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA | Format: Shapefile | Indonesia Geospatial portal"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling",
    "title": "Take Home Exercise 2",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nCheck for invalid geometries\n\n\nReference from senior sample submissions for code for this section, with credit to Megan’s Take-Home Exercise 1: Analysing and Visualising Spatio-temporal Patterns of COVID-19 in DKI Jakarta, Indonesia\n\nlength(which(st_is_valid(jakarta_data) == FALSE))\n\n[1] 0\n\n\n\n\nNo invalid geometries\n\nCheck for missing values\n\njakarta_data[rowSums(is.na(jakarta_data))!=0,]\n\nSimple feature collection with 2 features and 161 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 106.8412 ymin: -6.154036 xmax: 106.8612 ymax: -6.144973\nGeodetic CRS:  WGS 84\n    OBJECT_ID KODE_DESA             DESA   KODE    PROVINSI KAB_KOTA KECAMATAN\n243     25645  31888888     DANAU SUNTER 318888 DKI JAKARTA     <NA>      <NA>\n244     25646  31888888 DANAU SUNTER DLL 318888 DKI JAKARTA     <NA>      <NA>\n    DESA_KELUR JUMLAH_PEN JUMLAH_KK LUAS_WILAY KEPADATAN PERPINDAHA JUMLAH_MEN\n243       <NA>          0         0          0         0          0          0\n244       <NA>          0         0          0         0          0          0\n    PERUBAHAN WAJIB_KTP SILAM KRISTEN KHATOLIK HINDU BUDHA KONGHUCU KEPERCAYAA\n243         0         0     0       0        0     0     0        0          0\n244         0         0     0       0        0     0     0        0          0\n    PRIA WANITA BELUM_KAWI KAWIN CERAI_HIDU CERAI_MATI U0 U5 U10 U15 U20 U25\n243    0      0          0     0          0          0  0  0   0   0   0   0\n244    0      0          0     0          0          0  0  0   0   0   0   0\n    U30 U35 U40 U45 U50 U55 U60 U65 U70 U75 TIDAK_BELU BELUM_TAMA TAMAT_SD SLTP\n243   0   0   0   0   0   0   0   0   0   0          0          0        0    0\n244   0   0   0   0   0   0   0   0   0   0          0          0        0    0\n    SLTA DIPLOMA_I DIPLOMA_II DIPLOMA_IV STRATA_II STRATA_III BELUM_TIDA\n243    0         0          0          0         0          0          0\n244    0         0          0          0         0          0          0\n    APARATUR_P TENAGA_PEN WIRASWASTA PERTANIAN NELAYAN AGAMA_DAN PELAJAR_MA\n243          0          0          0         0       0         0          0\n244          0          0          0         0       0         0          0\n    TENAGA_KES PENSIUNAN LAINNYA GENERATED KODE_DES_1 BELUM_ MENGUR_ PELAJAR_\n243          0         0       0      <NA>       <NA>      0       0        0\n244          0         0       0      <NA>       <NA>      0       0        0\n    PENSIUNA_1 PEGAWAI_ TENTARA KEPOLISIAN PERDAG_ PETANI PETERN_ NELAYAN_1\n243          0        0       0          0       0      0       0         0\n244          0        0       0          0       0      0       0         0\n    INDUSTR_ KONSTR_ TRANSP_ KARYAW_ KARYAW1 KARYAW1_1 KARYAW1_12 BURUH BURUH_\n243        0       0       0       0       0         0          0     0      0\n244        0       0       0       0       0         0          0     0      0\n    BURUH1 BURUH1_1 PEMBANT_ TUKANG TUKANG_1 TUKANG_12 TUKANG__13 TUKANG__14\n243      0        0        0      0        0         0          0          0\n244      0        0        0      0        0         0          0          0\n    TUKANG__15 TUKANG__16 TUKANG__17 PENATA PENATA_ PENATA1_1 MEKANIK SENIMAN_\n243          0          0          0      0       0         0       0        0\n244          0          0          0      0       0         0       0        0\n    TABIB PARAJI_ PERANCA_ PENTER_ IMAM_M PENDETA PASTOR WARTAWAN USTADZ JURU_M\n243     0       0        0       0      0       0      0        0      0      0\n244     0       0        0       0      0       0      0        0      0      0\n    PROMOT ANGGOTA_ ANGGOTA1 ANGGOTA1_1 PRESIDEN WAKIL_PRES ANGGOTA1_2\n243      0        0        0          0        0          0          0\n244      0        0        0          0        0          0          0\n    ANGGOTA1_3 DUTA_B GUBERNUR WAKIL_GUBE BUPATI WAKIL_BUPA WALIKOTA WAKIL_WALI\n243          0      0        0          0      0          0        0          0\n244          0      0        0          0      0          0        0          0\n    ANGGOTA1_4 ANGGOTA1_5 DOSEN GURU PILOT PENGACARA_ NOTARIS ARSITEK AKUNTA_\n243          0          0     0    0     0          0       0       0       0\n244          0          0     0    0     0          0       0       0       0\n    KONSUL_ DOKTER BIDAN PERAWAT APOTEK_ PSIKIATER PENYIA_ PENYIA1 PELAUT\n243       0      0     0       0       0         0       0       0      0\n244       0      0     0       0       0         0       0       0      0\n    PENELITI SOPIR PIALAN PARANORMAL PEDAGA_ PERANG_ KEPALA_ BIARAW_ WIRASWAST_\n243        0     0      0          0       0       0       0       0          0\n244        0     0      0          0       0       0       0       0          0\n    LAINNYA_12 LUAS_DESA KODE_DES_3 DESA_KEL_1 KODE_12\n243          0         0       <NA>       <NA>       0\n244          0         0       <NA>       <NA>       0\n                          geometry\n243 MULTIPOLYGON (((106.8612 -6...\n244 MULTIPOLYGON (((106.8504 -6...\n\n\n\n\nRemove missing fields\n\njakarta_data <- na.omit(jakarta_data,c(\"DESA_KELUR\"))\n\n\n\n\nCheck coordinate system of data\n\nst_crs(jakarta_data)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\nNote: WGS84 is not appropriate, have to change to national coordinate system of Indonesia – DGN95\n\njakarta_data <- st_transform(jakarta_data, 23845)\n\n\nCheck if CRS changed\n\nst_crs(jakarta_data)\n\nCoordinate Reference System:\n  User input: EPSG:23845 \n  wkt:\nPROJCRS[\"DGN95 / Indonesia TM-3 zone 54.1\",\n    BASEGEOGCRS[\"DGN95\",\n        DATUM[\"Datum Geodesi Nasional 1995\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4755]],\n    CONVERSION[\"Indonesia TM-3 zone 54.1\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",139.5,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9999,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",200000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",1500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"easting (X)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"northing (Y)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre.\"],\n        AREA[\"Indonesia - onshore east of 138°E.\"],\n        BBOX[-9.19,138,-1.49,141.01]],\n    ID[\"EPSG\",23845]]\n\n\n\n\n\nRemoving redundant data\n\nWe are only interested in DKI Jakarta, hence we will be removing other islands or districts from the data.\n\n\nSince KAB-KOTA which is ‘City’ will be the best way to filter them, we take a look at the cities in this dataset.\n\nunique(jakarta_data$\"KAB_KOTA\")\n\n[1] \"JAKARTA BARAT\"    \"JAKARTA PUSAT\"    \"KEPULAUAN SERIBU\" \"JAKARTA UTARA\"   \n[5] \"JAKARTA TIMUR\"    \"JAKARTA SELATAN\" \n\n\n\n\n\n\nTranslation of column names for ease of handling data\n\nUsing rename() of dplyr package\n\njakarta_data <- jakarta_data %>% \n  dplyr::rename(\n    Object_ID=OBJECT_ID,\n    Province=PROVINSI, \n    City=KAB_KOTA, \n    District=KECAMATAN, \n    Village_Code=KODE_DESA, \n    Village=DESA, \n    Sub_District=DESA_KELUR,\n    Code=KODE, \n    Total_Population=JUMLAH_PEN\n    )\n\n\n\nVisualising to see all cities in this dataset\n\ntm_shape(jakarta_data) + \n  tm_polygons(\"Sub_District\")\n\nWarning: Number of levels of the variable \"Sub_District\" is 267, which is\nlarger than max.categories (which is 30), so levels are combined. Set\ntmap_options(max.categories = 267) in the layer function to show all levels.\n\n\nLegend labels were too wide. The labels have been resized to 0.35, 0.31, 0.30, 0.36, 0.38, 0.60, 0.34, 0.32, 0.44, 0.41, 0.27, 0.31, 0.30, 0.26, 0.25, 0.34, 0.30, 0.24, 0.35, 0.35, 0.33, 0.28, 0.25, 0.26, 0.27, 0.42, 0.42, 0.28, 0.25, 0.28. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger.\n\n\n\n\n\n\n\nRemoving redundant data\n\njakarta_data <- filter(jakarta_data, City != \"KEPULAUAN SERIBU\")\n\n\nNote: reduced from 267 observations to 261 observations\n\n\n\nRetaining first 9 fields of jakarta_data as per assignment instructions\n\njakarta_data <- jakarta_data %>% select(1:9)\n\n\nNote: reduced to 10 variables\n\n\n\n\nFinal visualisation of DKI Jakarta data\n\ntm_shape(jakarta_data) + \n  tm_polygons(\"Sub_District\")\n\nWarning: Number of levels of the variable \"Sub_District\" is 261, which is\nlarger than max.categories (which is 30), so levels are combined. Set\ntmap_options(max.categories = 261) in the layer function to show all levels.\n\n\nSome legend labels were too wide. These labels have been resized to 0.63, 0.42, 0.44, 0.49, 0.41, 0.50, 0.60, 0.59, 0.62, 0.61, 0.57, 0.57, 0.53, 0.59. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aspatial-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aspatial-data",
    "title": "Take Home Exercise 2",
    "section": "Aspatial Data",
    "text": "Aspatial Data"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aspatial-data-pre-processing-function",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aspatial-data-pre-processing-function",
    "title": "Take Home Exercise 2",
    "section": "Aspatial Data Pre-processing Function",
    "text": "Aspatial Data Pre-processing Function\n\n# takes in an aspatial data filepath and returns a processed output\naspatial_preprocess <- function(filepath){\n  # read xlsx file\n  result_file <- read_xlsx(filepath)\n  \n  # Create the Date Column\n  # the format of our files is: Vaccination DD MM YYYY Jarkarta\n  # Starting Point: Vaccination\n  # End Point: Jarkarta\n  # Use [1] to indicate first element in the list\n  # reference https://stackoverflow.com/questions/14249562/find-the-location-of-a-character-in-string\n  startpoint <- gregexpr(pattern=\"Vaccination\", filepath)[[1]] + 12\n  endpoint <- gregexpr(pattern=\"Jarkarta\", filepath)[[1]] - 2\n  result_file$Date <- substr(filepath, startpoint, endpoint)\n  \n  # Retain the Relevant Columns\n  result_file <- result_file %>% \n    select(\"Date\", \n           \"WILAYAH KOTA\", \n           \"KECAMATAN\", \n           \"KELURAHAN\", \n           \"SASARAN\", \n           \"BELUM VAKSIN\")\n  return(result_file)\n}"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#feed-files-into-preprocessing-function",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#feed-files-into-preprocessing-function",
    "title": "Take Home Exercise 2",
    "section": "Feed files into preprocessing function",
    "text": "Feed files into preprocessing function\n\n# in the folder 'data/aspatial', find files with the extension '.xlsx' and add it to our fileslist \n# the full.names=TRUE prepends the directory path to the file names, giving a relative file path - otherwise, only the file names (not the paths) would be returned \n# reference: https://stat.ethz.ch/R-manual/R-devel/library/base/html/list.files.html\nfileslist <-list.files(path = \"data/aspatial\", pattern = \"*.xlsx\", full.names=TRUE)\n\n# afterwards, for every element in fileslist, apply aspatial_process function\ndflist <- lapply(seq_along(fileslist), function(x) aspatial_preprocess(fileslist[x]))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#convert-dflist-into-actual-dataframe",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#convert-dflist-into-actual-dataframe",
    "title": "Take Home Exercise 2",
    "section": "Convert dflist into actual dataframe",
    "text": "Convert dflist into actual dataframe\n\ncases_jakarta <- ldply(dflist, data.frame)\n\n\nCheck cases_jakarta\n\nglimpse(cases_jakarta)\n\nRows: 3,216\nColumns: 6\n$ Date         <chr> \"01 Agustus 2021 \", \"01 Agustus 2021 \", \"01 Agustus 2021 …\n$ WILAYAH.KOTA <chr> NA, \"JAKARTA UTARA\", \"JAKARTA BARAT\", \"JAKARTA TIMUR\", \"J…\n$ KECAMATAN    <chr> NA, \"PADEMANGAN\", \"TAMBORA\", \"KRAMAT JATI\", \"JATINEGARA\",…\n$ KELURAHAN    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\", \"BALE KAMBANG\", \"BALI MESTER\",…\n$ SASARAN      <dbl> 8941211, 23947, 29381, 29074, 9752, 26285, 21566, 23886, …\n$ BELUM.VAKSIN <dbl> 4399496, 12155, 13727, 18226, 4987, 13716, 10232, 9999, 2…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#format-date-column",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#format-date-column",
    "title": "Take Home Exercise 2",
    "section": "Format Date Column",
    "text": "Format Date Column\n\n# parses the 'Date' column into Month(Full Name)-YYYY datetime objects\n# reference: https://stackoverflow.com/questions/53380650/b-y-date-conversion-gives-na\n\n# locale=\"ind\" means that the locale has been set as Indonesia\nSys.setlocale(locale=\"ind\")\n\nWarning in Sys.setlocale(locale = \"ind\"): using locale code page other than\n65001 (\"UTF-8\") may cause problems\n\n\n[1] \"LC_COLLATE=Indonesian_Indonesia.1252;LC_CTYPE=Indonesian_Indonesia.1252;LC_MONETARY=Indonesian_Indonesia.1252;LC_NUMERIC=C;LC_TIME=Indonesian_Indonesia.1252\"\n\n\n\ncases_jakarta$Date <- c(cases_jakarta$Date) %>% \n  as.Date(cases_jakarta$Date, format =\"%d %B %Y\")\nglimpse(cases_jakarta)\n\nRows: 3,216\nColumns: 6\n$ Date         <date> 2021-08-01, 2021-08-01, 2021-08-01, 2021-08-01, 2021-08-~\n$ WILAYAH.KOTA <chr> NA, \"JAKARTA UTARA\", \"JAKARTA BARAT\", \"JAKARTA TIMUR\", \"J~\n$ KECAMATAN    <chr> NA, \"PADEMANGAN\", \"TAMBORA\", \"KRAMAT JATI\", \"JATINEGARA\",~\n$ KELURAHAN    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\", \"BALE KAMBANG\", \"BALI MESTER\",~\n$ SASARAN      <dbl> 8941211, 23947, 29381, 29074, 9752, 26285, 21566, 23886, ~\n$ BELUM.VAKSIN <dbl> 4399496, 12155, 13727, 18226, 4987, 13716, 10232, 9999, 2~"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#renaming-columns",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#renaming-columns",
    "title": "Take Home Exercise 2",
    "section": "Renaming columns",
    "text": "Renaming columns\n\ncases_jakarta <- cases_jakarta %>%\n  dplyr::rename(\n    Date=Date,\n    City = WILAYAH.KOTA,\n    District = KECAMATAN,\n    Sub_District = KELURAHAN,\n    Target_vaccine = SASARAN,\n    Unvaccinated = BELUM.VAKSIN\n  )"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#removing-redundant-cities",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#removing-redundant-cities",
    "title": "Take Home Exercise 2",
    "section": "Removing redundant cities",
    "text": "Removing redundant cities\n\ncases_jakarta <- filter(cases_jakarta, City != \"KAB.ADM.KEP.SERIBU\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-integration-of-geospatial-and-aspatial",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-integration-of-geospatial-and-aspatial",
    "title": "Take Home Exercise 2",
    "section": "Data Integration of Geospatial and Aspatial",
    "text": "Data Integration of Geospatial and Aspatial\n\n# checks for column names of the dataframes\ncolnames(jakarta_data)\n\n [1] \"Object_ID\"        \"Village_Code\"     \"Village\"          \"Code\"            \n [5] \"Province\"         \"City\"             \"District\"         \"Sub_District\"    \n [9] \"Total_Population\" \"geometry\"        \n\n\n\ncolnames(cases_jakarta)\n\n[1] \"Date\"           \"City\"           \"District\"       \"Sub_District\"  \n[5] \"Target_vaccine\" \"Unvaccinated\"  \n\n\n\n# joins cases_jakarta to bd_jakarta based on Province, Sub_District and City\ncombined_jakarta <- left_join(jakarta_data, cases_jakarta,\n                              by=c(\n                                \"District\"=\"District\", \n                                \"Sub_District\"=\"Sub_District\",\n                                \"City\"=\"City\")\n                              )\n\n\nNow let’s visualise subdistrict in terms of unvaccinated and target vaccine\n\ntarget_vaccine <- tm_shape(combined_jakarta) +\n  tm_borders(alpha = 0.5) +\n  tm_fill(\"Target_vaccine\")\n\nnot_vaccinated <- tm_shape(combined_jakarta) +\n  tm_borders(alpha = 0.5) +\n  tm_fill(\"Unvaccinated\")\n\ntmap_arrange(target_vaccine, not_vaccinated)\n\n\n\n\n\n\nAs shown above, there are grey areas in the map. These are missing values which might be caused by mismatched records from joining subdistricts/city from the 2 dataframes."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#correcting-mismatched-records",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#correcting-mismatched-records",
    "title": "Take Home Exercise 2",
    "section": "Correcting mismatched records",
    "text": "Correcting mismatched records\n\nTo find, we see what was in jakarta_data but not in cases_jakarta\n\nvaccine_subdistrict <- c(cases_jakarta$Sub_District)\njakarta_subdistrict <- c(jakarta_data$Sub_District)\n\nunique(vaccine_subdistrict[!(vaccine_subdistrict %in% jakarta_subdistrict)])\n\n[1] \"BALE KAMBANG\"          \"HALIM PERDANA KUSUMAH\" \"JATI PULO\"            \n[4] \"KAMPUNG TENGAH\"        \"KERENDANG\"             \"KRAMAT JATI\"          \n[7] \"PAL MERIAM\"            \"PINANG RANTI\"          \"RAWA JATI\"            \n\n\n\nunique(jakarta_subdistrict[!(jakarta_subdistrict %in% vaccine_subdistrict)])\n\n[1] \"KRENDANG\"             \"RAWAJATI\"             \"TENGAH\"              \n[4] \"BALEKAMBANG\"          \"PINANGRANTI\"          \"JATIPULO\"            \n[7] \"PALMERIAM\"            \"KRAMATJATI\"           \"HALIM PERDANA KUSUMA\"\n\n\n\n\nLet us visualise the mismatched records\n\n\n\n\n\n\n\nGeospatial Data (jakarta_subdistrict)\nAspatial Data (vaccine_subdistrict)\n\n\n\n\nBALEKAMBANG\nBALE KAMBANG\n\n\nHALIM PERDANA KUSUMA\nHALIM PERDANA KUSUMAH\n\n\nJATIPULO\nJATI PULO\n\n\nTENGAH\nKAMPUNG TENGAH\n\n\nKRENDANG\nKERENDANG\n\n\nKRAMATJATI\nKRAMAT JATI\n\n\nPALMERIAN\nPAL MERIAN\n\n\nPINANGRANTI\nPINANG RANTI\n\n\nRAWAJATI\nRAWA JATI"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#renaming-mismatched-records",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#renaming-mismatched-records",
    "title": "Take Home Exercise 2",
    "section": "Renaming mismatched records",
    "text": "Renaming mismatched records\n\n# where bd_jakarta is a mismatched value, replace with the correct value\njakarta_data$Sub_District[jakarta_data$Sub_District == 'BALEKAMBANG'] <- 'BALE KAMBANG'\njakarta_data$Sub_District[jakarta_data$Sub_District == 'HALIM PERDANA KUSUMA'] <- 'HALIM PERDANA KUSUMAH'\njakarta_data$Sub_District[jakarta_data$Sub_District == 'JATIPULO'] <- 'JATI PULO'\njakarta_data$Sub_District[jakarta_data$Sub_District == 'TENGAH'] <- 'KAMPUNG TENGAH'\njakarta_data$Sub_District[jakarta_data$Sub_District == 'KRAMATJATI'] <- 'KRAMAT JATI'\njakarta_data$Sub_District[jakarta_data$Sub_District == 'KRENDANG'] <- 'KERENDANG'\njakarta_data$Sub_District[jakarta_data$Sub_District == 'PALMERIAM'] <- 'PAL MERIAM'\njakarta_data$Sub_District[jakarta_data$Sub_District == 'PINANGRANTI'] <- 'PINANG RANTI'\njakarta_data$Sub_District[jakarta_data$Sub_District == 'RAWAJATI'] <- 'RAWA JATI'"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#joining-both-dataframes-by-sub-district",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#joining-both-dataframes-by-sub-district",
    "title": "Take Home Exercise 2",
    "section": "Joining both dataframes by sub-district",
    "text": "Joining both dataframes by sub-district\n\ncombined_jakarta <- left_join(jakarta_data, cases_jakarta,\n                          by=c(\"Sub_District\" = \"Sub_District\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-data-once-again",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#visualising-data-once-again",
    "title": "Take Home Exercise 2",
    "section": "Visualising data once again",
    "text": "Visualising data once again\n\ntarget_vaccine <- tm_shape(combined_jakarta) +\n  tm_borders(alpha = 0.5) +\n  tm_fill(\"Target_vaccine\")\n\nnot_vaccinated <- tm_shape(combined_jakarta) +\n  tm_borders(alpha = 0.5) +\n  tm_fill(\"Unvaccinated\")\n\ntmap_arrange(target_vaccine, not_vaccinated)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#calculations",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#calculations",
    "title": "Take Home Exercise 2",
    "section": "Calculations",
    "text": "Calculations\n\nComputation of Monthly Vaccination Rate\n\nHere, we subtract the quantity of non-vaccinated to subtract from the number of Target Vaccine, and divide it to retrieve a percentage decimal of vaccination rate.\n\nvaccine_rate <- cases_jakarta %>%\n  inner_join(jakarta_data, by=c(\"Sub_District\" = \"Sub_District\")) %>%\n  group_by(Sub_District, Date) %>%\n  summarise(`vaccination_rate` = (Target_vaccine - Unvaccinated)/Target_vaccine)\n\n`summarise()` has grouped output by 'Sub_District'. You can override using the\n`.groups` argument.\n\n\n\nglimpse(vaccine_rate)\n\nRows: 3,132\nColumns: 3\nGroups: Sub_District [261]\n$ Sub_District     <chr> \"ANCOL\", \"ANCOL\", \"ANCOL\", \"ANCOL\", \"ANCOL\", \"ANCOL\",~\n$ Date             <date> 2021-07-01, 2021-08-01, 2021-09-01, 2021-10-01, 2021~\n$ vaccination_rate <dbl> 0.3491884, 0.4924208, 0.6184073, 0.7224287, 0.7509083~\n\n\n\nvaccine_rate_pivot <- vaccine_rate %>% ungroup() %>% pivot_wider(names_from = Date, values_from = vaccination_rate)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#mapping-monthly-vaccination-rate",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#mapping-monthly-vaccination-rate",
    "title": "Take Home Exercise 2",
    "section": "Mapping Monthly Vaccination Rate",
    "text": "Mapping Monthly Vaccination Rate\n\nConvert to sf dataframe first\n\ncombined_jakarta <- st_as_sf(combined_jakarta)\n\n\nvaccine_rate_pivot <- vaccine_rate_pivot %>% \n  left_join(jakarta_data, by=c(\"Sub_District\" = \"Sub_District\"))\nvaccine_rate_pivot <- st_as_sf(vaccine_rate_pivot)\n\n\n\nCreate map helper function for recursive map plotting\n\nmap_function <- function(df, varname) {\ntm_shape(df) +\n  tm_fill(varname,\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Vaccination Rate\") +\n  tm_layout(main.title = varname,\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha = 0.2)\n}\n\n\n\nExecuting the function\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntmap_arrange(map_function(vaccine_rate_pivot, \"2021-07-01\"),\n             map_function(vaccine_rate_pivot, \"2021-08-01\"),\n             map_function(vaccine_rate_pivot, \"2021-09-01\"),\n             map_function(vaccine_rate_pivot, \"2021-10-01\"))\n\n\n\n\n\ntmap_arrange(map_function(vaccine_rate_pivot, \"2021-11-01\"),\n             map_function(vaccine_rate_pivot, \"2021-12-01\"),\n             map_function(vaccine_rate_pivot, \"2022-01-01\"),\n             map_function(vaccine_rate_pivot, \"2022-02-01\"))\n\n\n\n\n\ntmap_arrange(map_function(vaccine_rate_pivot, \"2022-03-01\"),\n             map_function(vaccine_rate_pivot, \"2022-04-01\"),\n             map_function(vaccine_rate_pivot, \"2022-05-01\"),\n             map_function(vaccine_rate_pivot, \"2022-06-01\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#spatial-pattern-analysis",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#spatial-pattern-analysis",
    "title": "Take Home Exercise 2",
    "section": "Spatial Pattern Analysis",
    "text": "Spatial Pattern Analysis\n\nAs the palette darkens to a darker shade of blue, it shows a higher vaccination rate. With a varying shade of blue across the entire Jakarta region, it is observed that the vaccines administered were inconsistent – some sub-districts with higher vaccination rates in the first few months of the study period did not maintain as high during later parts of the study period. This could be due to the fact that their citizens in that area have been vaccinated and hence, vaccination efforts are stronger in other sub-districts subsequently."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#derive-contiguity-weights-using-queens-method-sfdep-package",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#derive-contiguity-weights-using-queens-method-sfdep-package",
    "title": "Take Home Exercise 2",
    "section": "Derive contiguity weights using Queen’s method (sfdep() package)",
    "text": "Derive contiguity weights using Queen’s method (sfdep() package)\n\nset.seed(1234)\n\n\nwm_idw <- vaccine_rate_pivot %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#compute-gi-values-of-vaccination-rates-for-each-month",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#compute-gi-values-of-vaccination-rates-for-each-month",
    "title": "Take Home Exercise 2",
    "section": "Compute Gi* values of vaccination rates for each month",
    "text": "Compute Gi* values of vaccination rates for each month\n\nHCSA_july2021 <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    `2021-07-01`, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_aug2021 <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    `2021-08-01`, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_sept2021 <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    `2021-09-01`, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_oct2021 <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    `2021-10-01`, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_nov2021 <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    `2021-11-01`, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_dec2021 <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    `2021-12-01`, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_jan2022 <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    `2022-01-01`, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_feb2022 <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    `2022-02-01`, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_mar2022 <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    `2022-03-01`, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_april2022 <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    `2022-04-01`, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_may2022 <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    `2022-05-01`, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\n\nHCSA_june2022 <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    `2022-06-01`, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#create-map-objects-of-gi-map-then-plot-the-map.",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#create-map-objects-of-gi-map-then-plot-the-map.",
    "title": "Take Home Exercise 2",
    "section": "Create map objects of Gi* map, then plot the map.",
    "text": "Create map objects of Gi* map, then plot the map.\n\nFor each map, only hot and cold spot areas are displyed. (p-value less than 0.05)\n\n#July 2021\nHCSA_july2021_sig <- HCSA_july2021  %>%\n  filter(p_sim < 0.05)\n\nHCSA_july2021_map <- tm_shape(HCSA_july2021) +\n                      tm_polygons() +\n                      tm_borders(alpha = 0.5) +\n                    tm_shape(HCSA_july2021_sig) +\n                      tm_fill(\"gi_star\") + \n                      tm_borders(alpha = 0.4) + \n                      tm_layout(main.title = \"July 2021\")\n\n#Aug 2021\nHCSA_aug2021_sig <- HCSA_aug2021  %>%\n  filter(p_sim < 0.05)\n\nHCSA_aug2021_map <-tm_shape(HCSA_aug2021) +\n                      tm_polygons() +\n                      tm_borders(alpha = 0.5) +\n                    tm_shape(HCSA_aug2021_sig) +\n                      tm_fill(\"gi_star\") + \n                      tm_borders(alpha = 0.4) + \n                      tm_layout(main.title = \"Aug 2021\")\n\n#Sept 2021\nHCSA_sept2021_sig <- HCSA_sept2021  %>%\n  filter(p_sim < 0.05)\n\nHCSA_sept2021_map <- tm_shape(HCSA_sept2021) +\n                      tm_polygons() +\n                      tm_borders(alpha = 0.5) +\n                    tm_shape(HCSA_sept2021_sig) +\n                      tm_fill(\"gi_star\") + \n                      tm_borders(alpha = 0.4) + \n                      tm_layout(main.title = \"Sept 2021\")\n\n#Oct 2021\nHCSA_oct2021_sig <- HCSA_oct2021  %>%\n  filter(p_sim < 0.05)\n\nHCSA_oct2021_map <-tm_shape(HCSA_oct2021) +\n                    tm_polygons() +\n                    tm_borders(alpha = 0.5) +\n                  tm_shape(HCSA_oct2021_sig) +\n                    tm_fill(\"gi_star\") + \n                    tm_borders(alpha = 0.4) + \n                      tm_layout(main.title = \"Oct 2021\")\n\n# Nov 2021\nHCSA_nov2021_sig <- HCSA_nov2021  %>%\n  filter(p_sim < 0.05)\n\nHCSA_nov2021_map <-tm_shape(HCSA_nov2021) +\n                    tm_polygons() +\n                    tm_borders(alpha = 0.5) +\n                  tm_shape(HCSA_nov2021_sig) +\n                    tm_fill(\"gi_star\") + \n                    tm_borders(alpha = 0.4) + \n                      tm_layout(main.title = \"Nov 2021\")\n# Dec 2021\nHCSA_dec2021_sig <- HCSA_dec2021  %>%\n  filter(p_sim < 0.05)\n\nHCSA_dec2021_map <-tm_shape(HCSA_dec2021) +\n                  tm_polygons() +\n                  tm_borders(alpha = 0.5) +\n                tm_shape(HCSA_dec2021_sig) +\n                  tm_fill(\"gi_star\") + \n                  tm_borders(alpha = 0.4) + \n                      tm_layout(main.title = \"Dec 2021\")\n\n# Jan 2022\nHCSA_jan2022_sig <- HCSA_jan2022  %>%\n  filter(p_sim < 0.05)\n\nHCSA_jan2022_map <- tm_shape(HCSA_jan2022) +\n                    tm_polygons() +\n                    tm_borders(alpha = 0.5) +\n                  tm_shape(HCSA_jan2022_sig) +\n                    tm_fill(\"gi_star\") + \n                    tm_borders(alpha = 0.4) + \n                      tm_layout(main.title = \"Jan 2022\")\n\n# Fen 2022\nHCSA_feb2022_sig <- HCSA_feb2022  %>%\n  filter(p_sim < 0.05)\n\nHCSA_feb_2022_map <- tm_shape(HCSA_feb2022) +\n                      tm_polygons() +\n                      tm_borders(alpha = 0.5) +\n                    tm_shape(HCSA_feb2022_sig) +\n                      tm_fill(\"gi_star\") + \n                      tm_borders(alpha = 0.4) + \n                      tm_layout(main.title = \"Feb 2022\")\n\n# Mar 2022\nHCSA_mar2022_sig <- HCSA_mar2022  %>%\n  filter(p_sim < 0.05)\n\nHCSA_mar2022_map <- tm_shape(HCSA_mar2022) +\n                      tm_polygons() +\n                      tm_borders(alpha = 0.5) +\n                    tm_shape(HCSA_mar2022_sig) +\n                      tm_fill(\"gi_star\") + \n                      tm_borders(alpha = 0.4) + \n                      tm_layout(main.title = \"Mar 2022\")\n\n#April 2022\nHCSA_april2022_sig <- HCSA_april2022  %>%\n  filter(p_sim < 0.05)\n\nHCSA_april2022_map <- tm_shape(HCSA_april2022) +\n                        tm_polygons() +\n                        tm_borders(alpha = 0.5) +\n                      tm_shape(HCSA_april2022_sig) +\n                        tm_fill(\"gi_star\") + \n                        tm_borders(alpha = 0.4) + \n                      tm_layout(main.title = \"April 2022\")\n\n# May 2022\nHCSA_may2022_sig <- HCSA_may2022  %>%\n  filter(p_sim < 0.05)\n\nHCSA_may2022_map <- tm_shape(HCSA_may2022) +\n                      tm_polygons() +\n                      tm_borders(alpha = 0.5) +\n                    tm_shape(HCSA_may2022_sig) +\n                      tm_fill(\"gi_star\") + \n                      tm_borders(alpha = 0.4) + \n                      tm_layout(main.title = \"May 2022\")\n\n# June 2022\nHCSA_june2022_sig <- HCSA_june2022  %>%\n  filter(p_sim < 0.05)\n\nHCSA_june2022_map <- tm_shape(HCSA_june2022) +\n                      tm_polygons() +\n                      tm_borders(alpha = 0.5) +\n                    tm_shape(HCSA_june2022_sig) +\n                      tm_fill(\"gi_star\") + \n                      tm_borders(alpha = 0.4) + \n                      tm_layout(main.title = \"Jun 2022\")\n\n\ntmap_arrange(HCSA_july2021_map, HCSA_aug2021_map, HCSA_sept2021_map, HCSA_oct2021_map)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\ntmap_arrange(HCSA_mar2022_map, HCSA_april2022_map, HCSA_may2022_map, HCSA_june2022_map)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#emerging-hotspot-analysis-ehsa",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#emerging-hotspot-analysis-ehsa",
    "title": "Take Home Exercise 2",
    "section": "Emerging Hotspot Analysis (EHSA)",
    "text": "Emerging Hotspot Analysis (EHSA)\n\nWe will be conducting an EHSA on the monthly vaccination rates to see how hot and coldspots evolve over time.\n\n\nBuild a time series cube\n\nspacetime() of sfdep will be used to create a spatio-temporal cube\n\nvaccine_rate_st <- spacetime(vaccine_rate, jakarta_data,\n                             .loc_col = \"Sub_District\",\n                             .time_col = \"Date\")\n\nvaccine_rate_st\n\nspacetime ────\n\n\nContext:`data`\n\n\n261 locations `Sub_District`\n\n\n12 time periods `Date`\n\n\n-- data context ----------------------------------------------------------------\n\n\n# A tibble: 3,132 x 3\n# Groups:   Sub_District [261]\n   Sub_District Date       vaccination_rate\n * <chr>        <date>                <dbl>\n 1 ANCOL        2021-07-01            0.349\n 2 ANCOL        2021-08-01            0.492\n 3 ANCOL        2021-09-01            0.618\n 4 ANCOL        2021-10-01            0.722\n 5 ANCOL        2021-11-01            0.751\n 6 ANCOL        2021-12-01            0.770\n 7 ANCOL        2022-01-01            0.789\n 8 ANCOL        2022-02-01            0.806\n 9 ANCOL        2022-03-01            0.808\n10 ANCOL        2022-04-01            0.811\n# ... with 3,122 more rows\n\n\n\nis_spacetime_cube(vaccine_rate_st)\n\n[1] TRUE\n\n\n\n\nThe TRUE return confirms that vaccine_rate_st object is indeed an time-space cube."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#deriving-spatial-weights",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#deriving-spatial-weights",
    "title": "Take Home Exercise 2",
    "section": "Deriving Spatial Weights",
    "text": "Deriving Spatial Weights\n\n# vaccine_nb <- vaccine_rate_st %>%\n#   activate(\"geometry\") %>%\n#   mutate(nb = include_self(st_contiguity(geometry)),\n#          wt = st_inverse_distance(nb, geometry,\n#                                   scale = 1,\n#                                   alpha = 1),\n#          .before = 1)%>%\n#   set_wts(\"wt\") %>%\n#   set_nbs(\"nb\")\n# \n# head(vaccine_nb)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-local-gi",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#computing-local-gi",
    "title": "Take Home Exercise 2",
    "section": "Computing Local Gi*",
    "text": "Computing Local Gi*\n\n# gi_stars <- vaccine_nb %>% \n#   group_by(`Date`) %>% \n#   mutate(gi_star = local_gstar_perm(\n#     vaccine_rate, nb, wt)) %>% \n#   tidyr::unnest(gi_star)\n# \n# gi_stars"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#man-kendall-test",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#man-kendall-test",
    "title": "Take Home Exercise 2",
    "section": "Man Kendall Test",
    "text": "Man Kendall Test\n\njune_rate <- vaccine_rate %>%\n  filter(Date == as.Date(\"2022-06-01\"))%>%\n  arrange(desc(`vaccination_rate`))\n\nhead(june_rate)\n\n# A tibble: 6 x 3\n# Groups:   Sub_District [6]\n  Sub_District          Date       vaccination_rate\n  <chr>                 <date>                <dbl>\n1 HALIM PERDANA KUSUMAH 2022-06-01            0.898\n2 SRENGSENG SAWAH       2022-06-01            0.878\n3 MANGGARAI SELATAN     2022-06-01            0.875\n4 MALAKA SARI           2022-06-01            0.871\n5 GLODOK                2022-06-01            0.870\n6 TEBET BARAT           2022-06-01            0.870\n\n\n\nThe 3 sub-districts with the highest vaccination rates are: HALIM PERDANA KUSUMAH, SRENGSENG SAWAH and MANGGARAI SELATAN."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#observing-these-3-sub-districts-for-man-kendall-test",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#observing-these-3-sub-districts-for-man-kendall-test",
    "title": "Take Home Exercise 2",
    "section": "Observing these 3 sub-districts for Man Kendall Test",
    "text": "Observing these 3 sub-districts for Man Kendall Test\n\n#HALIM PERDANA KUSUMAH\n\n# cbg_hpk <- gi_stars %>% \n#   ungroup() %>% \n#   filter(Sub_District == \"HALIM PERDANA KUSUMAH\") |> \n#   select(Sub_District, Date, gi_star)\n# \n# ggplot(data = cbg_hpk, \n#        aes(x = Date, \n#            y = gi_star)) +\n#   geom_line() +\n#   theme_light()\n\n\n#SRENGSENG SAWAH\n\n# cbg_ss <- gi_stars %>% \n#   ungroup() %>% \n#   filter(Sub_District == \"SRENGSENG SAWAH\") |> \n#   select(Sub_District, Date, gi_star)\n# \n# ggplot(data = cbg_ss, \n#        aes(x = Date, \n#            y = gi_star)) +\n#   geom_line() +\n#   theme_light()\n\n\n#MANGGARAI SELATAN\n\n# cbg_ms <- gi_stars %>% \n#   ungroup() %>% \n#   filter(Sub_District == \"MANGGARAI SELATAN\") |> \n#   select(Sub_District, Date, gi_star)\n# \n# ggplot(data = cbg_ms, \n#        aes(x = Date, \n#            y = gi_star)) +\n#   geom_line() +\n#   theme_light()"
  }
]